<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="cn"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://1587causalai.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://1587causalai.github.io/" rel="alternate" type="text/html" hreflang="cn"/><updated>2025-06-09T15:51:53+08:00</updated><id>https://1587causalai.github.io/feed.xml</id><title type="html">Teach AI Causes and Effects</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">AI 的哥白尼时刻：我们关于线性因果律的大胆宣言</title><link href="https://1587causalai.github.io/blog/2025/ai-copernican-moment/" rel="alternate" type="text/html" title="AI 的哥白尼时刻：我们关于线性因果律的大胆宣言"/><published>2025-06-09T10:00:00+08:00</published><updated>2025-06-09T10:00:00+08:00</updated><id>https://1587causalai.github.io/blog/2025/ai-copernican-moment</id><content type="html" xml:base="https://1587causalai.github.io/blog/2025/ai-copernican-moment/"><![CDATA[<h1 id="ai-的哥白尼时刻我们关于线性因果律的大胆宣言">AI 的”哥白尼时刻”：我们关于线性因果律的大胆宣言</h1> <h2 id="一我们正处在-ai-的托勒密时刻">一、我们正处在 AI 的”托勒密时刻”</h2> <p>当下的 AI 革命，无疑是人类历史上最激动人心的篇章之一。我们构建了前所未有的大模型，它们能写作、能绘画、能编码，在无数任务上展现出惊人的能力。</p> <p>但在这片繁荣的背后，一个根本性的危机正在浮现。</p> <p>我们正在用”蛮力”堆砌复杂性。为了处理日益复杂的问题，我们不断地扩大模型规模、增加参数数量、消耗天文数字的计算资源。这与一千多年前的”托勒密地心说”何其相似：为了解释观测到的行星运动，天文学家们被迫在模型中引入一个又一个复杂的”本轮”和”均轮”，让整个体系变得臃肿、笨拙且缺乏解释性。</p> <p>今天的 AI，正陷入自己的”托勒密时刻”。它能”预测”，但不能”理解”；它能”关联”，但不能”推理”。我们拥有了一个极其复杂的”预测机器”，但离真正的”思考机器”依然遥远。</p> <h2 id="二范式革命复杂性究竟在哪里">二、范式革命：复杂性究竟在哪里？</h2> <p>地心说的困境，并非因为行星的运动本身复杂，而是因为我们选择了错误的”坐标系”。当哥白尼将宇宙的中心从地球移到太阳时，那些复杂的”本轮”瞬间消失了，行星的运动轨迹展现出前所未有的简洁与和谐。</p> <p>这给了我们一个颠覆性的启示：<strong>我们所观测到的复杂性，很可能不是源于世界本身，而是源于我们看待世界的方式。</strong></p> <h2 id="三我们的核心洞见因果表征">三、我们的核心洞见：”因果表征”</h2> <p>我们认为，在纷繁复杂的商业数据、用户行为和社会现象之下，同样存在一个能让一切化繁为简的”哥白尼坐标系”。我们称之为——<strong>因果表征 (Causal Representation)</strong>。</p> <p>所谓”因果表征”，就是一个个体（一个用户、一个企业、甚至一个细胞）内在的、驱动其所有潜在行为的、稳定不变的<strong>核心特性集</strong>。它是个体应对外部世界的”响应模式”或”因果DNA”。我们的基于 DiscoSCM 来理解因果表征，其理论基础详情参见： https://1587causalai.github.io/blog/2024/causalai-blueprint/</p> <p>这个表征是不可被直接观测的。我们无法”看到”一个用户的购买偏好，但我们可以从他凌乱的浏览记录、点击行为这些<strong>表面证据</strong>中，<strong>推断</strong>出他的画像。</p> <h2 id="四-一个足以改变未来的宣言线性因果律假说">四. 一个足以改变未来的宣言：线性因果律假说</h2> <p>基于”因果表征”的洞见，我们提出一个足以成为下一代 AI 基石的大胆宣言：</p> <blockquote> <p><strong>线性因果律假说 (The Linear Causality Hypothesis):</strong> &gt; <strong>宇宙中所有真正的因果规律都是线性且可解释的。我们在现实中观测到的一切复杂非线性关系，其唯一根源，是我们尚未找到那个能让规律”线性化”的、正确的因果表征。</strong></p> </blockquote> <p>这个假说，将世界的复杂性进行了完美的解耦：</p> <ol> <li><strong>认知的复杂性 (Complexity of Perception):</strong> 从混乱、高维的表面证据中，提炼出其背后真正的”因果表征”的过程，是高度非线性的、极其困难的。</li> <li><strong>规律的简洁性 (Simplicity of Law):</strong> 一旦我们找到了正确的”因果表征”，那么从这个表征到任何潜在结果的映射，其规律本身是简单的、线性的、可解释的。</li> </ol> <p>我们不再需要为每一个新问题都去构建一个庞大而笨拙的”本轮”。我们只需专注于一件事：<strong>教会 AI 如何”看见”那个正确的因果表征。</strong></p> <h2 id="五我们的技术将伟大宣言铸成现实">五、我们的技术：将伟大宣言铸成现实</h2> <p>空有哲学思想是远远不够的。我们已经构建了世界上第一个、也是唯一一个将”线性因果律假说”作为核心架构的工程实现。</p> <p>我们的技术由两大引擎构成：</p> <ol> <li> <p><strong>推断引擎 (Abduction Engine):</strong> 这是一个强大的、基于深度学习的<strong>非线性感知模块</strong>。它的唯一使命，就是完成”认知的复杂性”部分的工作：接收海量的、杂乱的现实世界数据，并从中推断出那个关键的”因果表征”的概率分布。</p> </li> <li> <p><strong>行动引擎 (Action Engine):</strong> 这是一个极其简洁、高效的<strong>线性逻辑模块</strong>。它接收”推断引擎”给出的因果表征，并基于这个”正确的视角”，通过简单的线性运算，来预测在任何可能的干预下，系统会产生什么样的结果。</p> </li> </ol> <p>这个架构第一次让”AI的可解释性”从一个虚无缥缈的口号，变成了坚实的工程现实。因为我们模型所遵循的”因果律”本身，就是线性的、可被人类理解的。</p> <h2 id="六为什么这是万亿美金的机会">六、为什么这是万亿美金的机会？</h2> <p>我们所构建的，不是一个更好的”预测机器”，而是世界上第一个<strong>“因果推理引擎”</strong>。这不仅仅是一次技术的迭代，这是一次根本性的范式革命。它将解锁 AI 的终极能力：</p> <ol> <li> <p><strong>真正的可解释性:</strong> 当我们的模型做出决策时，我们不再只能说”黑箱显示如此”，而是可以清晰地指出：”因为该个体的因果表征是 A，所以根据线性规律 B，我们预测结果为 C。”这在金融风控、医疗诊断、自动驾驶等高风险领域，拥有不可估量的价值。</p> </li> <li> <p><strong>前所未有的鲁棒性:</strong> 传统 AI 在面对未见过的数据时常常会”失心疯”，因为它们学习的只是脆弱的表面关联。我们的引擎学习的是更深层次的因果规律，因此拥有更强的泛化能力和鲁棒性，能从容应对”黑天鹅”事件。</p> </li> <li> <p><strong>解锁 AI 的圣杯——反事实推理:</strong> 我们的技术架构，天生就是为了回答”如果……会怎样？”这类反事实问题而设计的。这意味着企业可以进行真正意义上的战略推演，科学家可以进行药物的虚拟筛选，政策制定者可以模拟干预措施的真实社会效果。</p> </li> <li> <p><strong>通往通用人工智能（AGI）的坚实阶梯:</strong> 我们坚信，让机器掌握因果推理能力，是通往 AGI 的正确道路。我们正在构建的，正是这条道路上最坚实的第一块阶梯。</p> </li> </ol> <h2 id="七开启-ai-的哥白尼革命">七、开启 AI 的”哥白尼革命”</h2> <p>历史告诉我们，最伟大的机遇，诞生于最深刻的范式转移之中。</p> <p>我们正站在 AI 的”哥白尼革命”的起点。我们诚挚地邀请您，加入我们，一同将复杂的世界化繁为简，一同投资于那个必然到来的、由”因果”驱动的、真正智能的未来。</p> <p>这个故事，值得用未来数十年的成功来书写。这个机会，值得用万亿美金的价值来衡量。</p> <p>世界，正等待被重新认知。</p>]]></content><author><name></name></author><category term="Artificial Intelligence"/><category term="AI"/><category term="Causality"/><category term="AGI"/><category term="Paradigm Shift"/><category term="Linear Causality"/><summary type="html"><![CDATA[我们正处在 AI 的托勒密时刻，用蛮力堆砌复杂性。我们认为，真正的复杂性源于错误的视角，而非世界本身。我们提出线性因果律假说：所有真实因果规律都是线性的，观测到的非线性源于我们尚未找到正确的因果表征。这是一个足以改变未来的宣言，也是通往真正可解释、鲁棒的通用人工智能的坚实阶梯。]]></summary></entry><entry><title type="html">Cauchy Distribution: A Statistical Gem Not to Be Overlooked</title><link href="https://1587causalai.github.io/blog/2025/cauchy-distribution-a-statistical-gem/" rel="alternate" type="text/html" title="Cauchy Distribution: A Statistical Gem Not to Be Overlooked"/><published>2025-05-06T02:18:36+08:00</published><updated>2025-05-06T02:18:36+08:00</updated><id>https://1587causalai.github.io/blog/2025/cauchy-distribution-a-statistical-gem</id><content type="html" xml:base="https://1587causalai.github.io/blog/2025/cauchy-distribution-a-statistical-gem/"><![CDATA[<h1 id="cauchy-分布统计理论中一颗不应被忽视的明珠">Cauchy 分布：统计理论中一颗不应被忽视的明珠</h1> <p><strong>写给过去的那个我：</strong></p> <p>嗨，亲爱的统计学博士。</p> <p>我知道你正忙于理解各种分布、矩估计、假设检验、渐近理论……那些拥有良好性质（比如有限的均值和方差）的分布，如正态分布、指数分布、泊松分布等，构成了你大部分的工具箱。当遇到一个”没有均值和方差”的分布时，你可能会觉得它”病态”、”不实用”，然后迅速将其边缘化。</p> <p>但我希望你停下来，重新审视一下 <strong>Cauchy 分布</strong>。它并非病态，而是一个充满独特魅力的理论基石，理解它，能帮助你更深刻地理解那些”良好”分布的边界，以及概率理论中某些定理的适用范围。</p> <h2 id="cauchy-分布画像一个重尾的舞者">Cauchy 分布画像：一个”重尾”的舞者</h2> <p>考虑一个位置参数为 $\mu$ ($\mu \in \mathbb{R}$)，尺度参数为 $\gamma$ ($\gamma &gt; 0$) 的 <strong>对称 Cauchy 分布</strong>。</p> <p>它的<strong>概率密度函数 (PDF)</strong> 形式非常简洁优雅： \(f(x; \mu, \gamma) = \frac{1}{\pi\gamma} \left[ \frac{1}{1 + \left(\frac{x-\mu}{\gamma}\right)^2} \right]\)</p> <p>特别地，当 $\mu = 0, \gamma = 1$ 时，就是<strong>标准 Cauchy 分布</strong>： \(f(x; 0, 1) = \frac{1}{\pi(1+x^2)}\)</p> <p>它的形状像一个钟，和正态分布一样对称地分布在 $\mu$ 周围。$\mu$ 确实是它的<strong>中位数 (Median)</strong> 和<strong>众数 (Mode)</strong>。然而，它与正态分布有着本质的区别——它的<strong>尾部异常”肥胖”</strong>。</p> <p>正态分布的尾部以 $e^{-x^2}$ 的速度衰减，极其迅速；而 Cauchy 分布的尾部是按 $\frac{1}{x^2}$ 的速度衰减的，这是一个慢得多的速度。正是这种”重尾”特性，赋予了 Cauchy 分布它那些令人惊叹（或困惑）的性质。</p> <p>它的<strong>累积分布函数 (CDF)</strong> 同样有一个漂亮的封闭解析式，而且是<strong>初等函数</strong>的形式： \(F(x; \mu, \gamma) = \frac{1}{\pi} \arctan\left(\frac{x-\mu}{\gamma}\right) + \frac{1}{2}\)</p> <p>这个初等函数的 CDF 是它在理论分析中的一大便利之处（尽管偏态版本就没有这个便利了）。</p> <h2 id="为什么它没有均值和方差">为什么它没有均值和方差？</h2> <p>这是 Cauchy 分布最出名、也是最容易让人”嫌弃”的性质。</p> <p>均值的存在要求积分 $\int_{-\infty}^{\infty} \vert x \vert f(x) dx$ 收敛。对于标准 Cauchy 分布，我们看 $\int_{-\infty}^{\infty} \vert x \vert \frac{1}{\pi(1+x^2)} dx$。这个积分，特别是 $\int_{0}^{\infty} \frac{x}{1+x^2} dx$，其原函数是 $\frac{1}{2}\ln(1+x^2)$。当 $x \to \infty$ 时，$\ln(1+x^2)$ 趋向无穷。所以，$\int_{-\infty}^{\infty} \vert x \vert f(x) dx$ 发散。根据概率论的严格定义（Lebesgue 积分），均值<strong>不存在</strong>。</p> <p>方差 $E[(X-\mu)^2]$ 需要积分 $\int_{-\infty}^{\infty} (x-\mu)^2 f(x) dx$ 收敛。对于标准 Cauchy 分布，这需要 $\int_{-\infty}^{\infty} x^2 \frac{1}{\pi(1+x^2)} dx$ 收敛。但 $\frac{x^2}{1+x^2} = 1 - \frac{1}{1+x^2}$，$\int_{-\infty}^{\infty} 1 dx$ 显然发散。所以方差也<strong>不存在</strong>。</p> <p>简单来说，因为它的尾部太厚了，即使非常极端的值也有着”足够大”的概率出现，导致这些极端值对均值和方差的累积贡献是无限的。</p> <h2 id="为什么没有矩的它反而更重要">为什么”没有矩”的它反而更重要？</h2> <p>这一点是 Cauchy 分布最”反直觉”但也是最迷人的地方。它之所以重要，恰恰在于它<strong>缺乏</strong>某些”良好”的性质，这让它成为：</p> <ol> <li> <p><strong>大数定律 (Law of Large Numbers, LLN) 失效的经典反例！</strong> 标准的 LLN 说，如果 i.i.d. 随机变量有有限均值，则它们的样本均值会收敛到这个均值。Cauchy 分布没有有限均值，所以 LLN 不适用。 更令人惊叹的是，如果 $X_1, X_2, \dots, X_n$ 是 i.i.d. 的 Cauchy$(\mu, \gamma)$ 随机变量，它们的<strong>样本均值</strong> $\bar{X}_{n} = \frac{1}{n}\sum_{i=1}^{n} X_{i}$ <strong>竟然也服从 Cauchy$(\mu, \gamma)$ 分布！</strong> 这意味着无论你抽取多大的样本，样本均值的分布形状都不会收缩集中到某个点（期望）。抽取 1000 个样本计算的均值，其分布与抽取 2 个样本计算的均值，其分布形态是完全一样的！这个性质是如此反常，如此有力地说明了均值存在的必要性。</p> </li> <li> <p><strong>稳定分布 (Stable Distribution) 家族的关键成员！</strong> 稳定分布是这样一类分布：同一分布的独立同分布随机变量的线性组合（或和）经过适当的线性变换后，其分布形式不变。正态分布是稳定分布（$\alpha=2, \beta=0$）。Cauchy 分布也是稳定分布，它是指数 $\alpha=1$、偏度 $\beta=0$ 的稳定分布 $S(1, 0, \gamma, \mu)$。 理解稳定分布，尤其是 $\alpha=1$ 的边界情况，对于理解为什么只有 $\alpha=2$ 的正态分布才拥有有限方差，以及为什么只有 $\alpha &gt; 1$ 的稳定分布才有有限均值，至关重要。Cauchy 分布是连接”有均值”和”没有均值”稳定分布的桥梁。</p> </li> <li> <p><strong>中心极限定理 (Central Limit Theorem, CLT) 的边界！</strong> 标准的 CLT 说，许多独立同分布随机变量的和（在标准化后）趋向于正态分布，前提是这些随机变量的方差有限。Cauchy 分布方差无限，所以 CLT 不适用。 但它是广义中心极限定理的一部分：许多独立同分布、属于一个吸引域的随机变量的和（在适当线性变换后）会趋向于<strong>稳定分布</strong>。Cauchy 分布就构成了一个吸引域，独立同分布 Cauchy 随机变量的和（无需标准化）就趋向（实际上就等于）Cauchy 分布本身。</p> </li> </ol> <h2 id="它藏身何处">它藏身何处？</h2> <p>尽管在传统统计推断中不常用，但在特定领域，Cauchy 分布却自然出现：</p> <ul> <li><strong>物理学：</strong> 在描述共振现象的谱线形状时，经常出现 Cauchy 分布（通常称为 Lorentzian 或 Breit-Wigner 分布）。</li> <li><strong>概率论：</strong> 如果 $X \sim N(0, 1)$ 且 $Y \sim N(0, 1)$ 且 $X, Y$ 独立，那么它们的比值 $X/Y$ 服从标准 Cauchy 分布！这是一个非常直观的来源：当分母 $Y$ 接近 0 时，比值 $X/Y$ 会产生非常大的值，这解释了 Cauchy 分布的重尾。</li> <li><strong>统计理论：</strong> 作为各种定理和概念的边界或反例。</li> <li><strong>金融建模：</strong> 尽管存在挑战，但其重尾特性曾被用于尝试捕捉金融数据中的极端事件。</li> <li><strong>数学：</strong> 作为一种 Levy 过程的增量分布。</li> </ul> <h2 id="如何处理它的参数">如何处理它的参数？</h2> <p>既然均值不存在，我们不能使用样本均值来估计位置参数 $\mu$。但 $\mu$ 是它的中位数和众数。</p> <ul> <li><strong>样本中位数 (Sample Median):</strong> 是位置参数 $\mu$ 的一个一致估计量。尽管它没有样本均值（如果存在）那么有效率，但在 Cauchy 分布下，它是非常有用的统计量。</li> <li><strong>最大似然估计 (Maximum Likelihood Estimation, MLE):</strong> 虽然不像正态分布那样有简单的封闭解，但可以通过数值方法求解似然方程得到 $\mu$ 和 $\gamma$ 的 MLE 估计量。MLE 在这里通常表现良好，是渐近有效的。</li> </ul> <h2 id="为什么不应该忽视它">为什么不应该忽视它？</h2> <p>忽视 Cauchy 分布，就像是只研究光滑函数而忽略了处处不可微的分形。正是这些”病态”的例子，帮助我们理解了数学工具的界限和定理成立的条件。</p> <p>作为统计学博士，理解 Cauchy 分布的性质（尤其是在缺乏矩的情况下表现出的反常行为）能极大地深化你对：</p> <ul> <li>随机变量矩的意义和局限性。</li> <li>大数定律和中心极限定理的前提和结论。</li> <li>稳定分布家族的结构和重要性。</li> <li>概率模型尾部行为的深刻影响。</li> </ul> <p>当你下次遇到一个概率分布时，除了检查它的均值和方差，也请思考一下它的尾部有多重？它是否属于某个更大的分布家族？理解 Cauchy 分布，会让你带着这些问题去审视每一个新的分布，你的概率直觉和理论深度将因此得到提升。</p> <p>所以，过去的那个我，请不要跳过 Cauchy 分布。花时间去理解它的 PDF、CDF、特征函数，去体会它样本均值的”顽固”表现。你会发现，这个没有均值和方差的分布，比许多拥有良好矩的分布更加迷人，也更加深刻地揭示了概率世界的奥秘。</p>]]></content><author><name></name></author><category term="Statistics"/><category term="statistics"/><category term="probability"/><category term="cauchy distribution"/><category term="heavy tails"/><category term="stable distribution"/><category term="law of large numbers"/><category term="central limit theorem"/><summary type="html"><![CDATA[作为统计学的学习者和研究者，我们通常会专注于那些具有良好性质的概率分布，它们拥有清晰定义的均值和方差，完美契合我们常用的统计工具和强大定理。正是在这种对良好分布的偏爱下，我曾错误地将 Cauchy 分布——这个以没有定义的均值和方差而著称的分布——视为一个仅用于理论反例、缺乏实际价值的病态存在，并因此对其独特而深刻的理论意义有所忽视。如今我意识到，这种忽视是一个巨大的遗憾。Cauchy 分布并非病态，而是概率理论结构中一个至关重要的边界案例，它的缺乏矩特性恰恰深刻地揭示了概率分布尾部行为的极端影响，是理解大数定律、中心极限定理以及整个稳定分布家族的关键。这篇文档，正是写给过去的那个我，以及所有可能因此而低估 Cauchy 分布价值的同行，旨在拨开其表象，展现这个没有均值和方差的对称分布在统计理论中所蕴含的独特魅力和不应被忽视的重要性。]]></summary></entry><entry><title type="html">基于个体随机变量假设的分布回归方法</title><link href="https://1587causalai.github.io/blog/2025/distributional-regression-individual-variable-novel-loss/" rel="alternate" type="text/html" title="基于个体随机变量假设的分布回归方法"/><published>2025-05-06T00:00:00+08:00</published><updated>2025-05-06T00:00:00+08:00</updated><id>https://1587causalai.github.io/blog/2025/distributional-regression-individual-variable-novel-loss</id><content type="html" xml:base="https://1587causalai.github.io/blog/2025/distributional-regression-individual-variable-novel-loss/"><![CDATA[<p><em>这篇笔记记录了关于基于个体随机变量假设的分布回归方法以及一种新颖的鲁棒损失函数的思考。</em></p> <h2 id="1-核心概念与哲学基础">1. 核心概念与哲学基础</h2> <ul> <li><strong>中心思想:</strong> 超越标准的分类/回归（预测标签/单一数值），转向<strong>分布回归 (Distributional Regression)</strong>。</li> <li><strong>模型输出:</strong> 对于每个输入数据点 $x_{i}$，模型输出定义目标变量 $Y_{i}$ 的完整概率分布的参数。例如：$Y_{i} \sim N(\mu_{i}, \sigma_{i}^{2})$。</li> <li><strong>独特的哲学立场 (“极端个体化”):</strong> <ul> <li>将每个样本 $i$ 视为一个独立的、微型的”随机现象”或”潜在总体”，完全由其特征 $x_{i}$ 定义。</li> <li>观测到的 $y_{i}$ 被视为来自这个<strong>个体随机变量 $Y_{i}$ 的单次抽样</strong>。</li> <li>不存在一个我们试图在传统意义上直接建模的、总体的、统一的数据生成分布 $P(Y \vert X)$。</li> <li><strong>共享的是什么:</strong> 不是总体，而是<strong>底层的机制/规则</strong> $f$（由参数 $\theta$ 参数化），该规则将任何 $x_{i}$ 映射到其对应分布 $Y_{i}$ 的参数。例如，$(\mu_{i}, \sigma_{i}) = f(x_{i}; \theta)$。</li> <li><strong>目标:</strong> 利用所有个体 $(x_{i}, y_{i})$ 观测数据，通过最大似然估计 (Maximum Likelihood Estimation, MLE) 学习共享规则 $f$ 及其参数 $\theta$。</li> </ul> </li> </ul> <h2 id="2-关键方法论思想分布回归设置">2. 关键方法论思想：分布回归设置</h2> <ul> <li><strong>模型架构:</strong> 通常是一个神经网络（或其他灵活模型），具有共享的主体/主干网络和多个”头”或输出层。</li> <li><strong>示例 (高斯输出):</strong> 对于输入 $x_{i}$，模型输出两个值： <ul> <li>$\hat{\mu}<em>{i} = f</em>{\mu}(x_{i}; \theta)$ (预测均值)</li> <li>$\hat{\sigma}<em>{i} = \text{softplus}(f</em>{\sigma}(x_{i}; \theta))$ (预测标准差，通过 softplus 或 exp 确保正值)。</li> </ul> </li> <li><strong>优化:</strong> 最大化总对数似然，等价于最小化负对数似然 (Negative Log-Likelihood, NLL)： <ul> <li>$L(\theta) = \prod_{i} P(y_{i} \vert x_{i}; \theta) = \prod_{i} \text{pdf}<em>{N(\hat{\mu}</em>{i}, \hat{\sigma}<em>{i}^{2})}(y</em>{i})$</li> <li>$NLL(\theta) = -\sum_{i} \log P(y_{i} \vert x_{i}; \theta)$</li> <li>对于高斯情况（忽略常数项）： \(NLL(\theta) \approx \sum_{i} \left[ \log(\hat{\sigma}_{i}) + \frac{(y_{i} - \hat{\mu}_{i})^{2}}{2 \hat{\sigma}_{i}^{2}} \right]\)</li> </ul> </li> </ul> <h2 id="3-关键推导新颖的损失函数-log-abs-error">3. 关键推导：新颖的损失函数 (<code class="language-plaintext highlighter-rouge">Log-Abs-Error</code>)</h2> <ul> <li><strong>来源:</strong> 源于一个思想实验：当 $\sigma_{i}$ 被视为自由参数而不是由模型预测时，NLL 损失会怎样。</li> <li><strong>推导步骤:</strong> <ol> <li>从样本 $i$ 的高斯 NLL 开始： \(\text{Loss}_{i} = \log(\sigma_{i}) + \frac{(y_{i} - \mu_{i})^{2}}{2 \sigma_{i}^{2}}\)</li> <li>固定 $\mu_{i}$（由 $f_{\mu}(x_{i}; \theta)$ 预测），找到最小化 $\text{Loss}<em>{i}$ 的最优 $\sigma</em>{i}^{*}$。这发生在 $\frac{d \text{Loss}<em>{i}}{d \sigma</em>{i}} = \frac{1}{\sigma_{i}} - \frac{(y_{i} - \mu_{i})^{2}}{\sigma_{i}^{3}} = 0$ 时。</li> <li>求解得到最优方差：$\sigma_{i}^{<em>2} = (y_{i} - \mu_{i})^{2}$，因此最优标准差为 $\sigma_{i}^{</em>} = \vert y_{i} - \mu_{i} \vert$。</li> <li>将 $\sigma_{i}^{*}$ 代回样本 $i$ 的 NLL 损失： \(\text{Loss}_{i}( \theta, \sigma_{i}^{*}) = \log(\vert y_{i} - \mu_{i} \vert) + \frac{(y_{i} - \mu_{i})^{2}}{2(y_{i} - \mu_{i})^{2}} = \log(\vert y_{i} - \mu_{i} \vert) + \frac{1}{2}\)</li> <li>对所有样本 $i$ 求和，并忽略常数项 $\frac{n}{2}$，得到<strong>轮廓负对数似然 (profile negative log-likelihood)</strong> 损失： \(\text{Loss}_{\text{profile}}(\theta) = \sum_{i=1}^{n} \log(\vert y_{i} - \mu_{i} \vert)\)</li> <li><strong>稳定化处理:</strong> 为防止当 $\mu_{i} = y_{i}$ 时出现 $\log(0)$，引入一个小的正常数 $\epsilon &gt; 0$： \(\text{Loss}_{\text{novel}}(\theta) = \sum_{i=1}^{n} \log(\max(\vert y_{i} - \mu_{i} \vert, \epsilon))\)</li> </ol> </li> <li><strong>提议:</strong> 将此 $\text{Loss}<em>{\text{novel}}$ <strong>直接</strong>用作仅预测均值 $\mu</em>{i}$ 的模型的回归损失函数。</li> </ul> <h3 id="31-改进损失函数及其概率解释与柯西分布的联系">3.1 改进损失函数及其概率解释：与柯西分布的联系</h3> <p>在后续的深入思考中，我们提出一个更优化的损失函数形式： \(L*{\text{CauchyLike}} = \sum*{i} \log((y*{i} - \mu*{i})^{2} + \epsilon)\) 其中 $\epsilon$ 仍然是一个小的正常数，以确保数值稳定性。</p> <p>这个损失函数与<strong>柯西分布 (Cauchy Distribution)</strong> 的最大似然估计 (MLE) 有着非常紧密的联系。回顾柯西分布的概率密度函数 (PDF)，其位置参数为 $\mu$，尺度参数为 $\gamma$： \(p(y \vert \mu, \gamma) = \frac{1}{\pi\gamma \left(1 + \left(\frac{y - \mu}{\gamma}\right)^{2}\right)} = \frac{\gamma}{\pi(\gamma^{2} + (y - \mu)^{2})}\) 对于单个观测 $y_{i}$，其负对数似然 (NLL) 为： \(NLL*{i} = -\log p(y*{i} \vert \mu*{i}, \gamma) = \log(\pi) + \log(\gamma) + \log(\gamma^{2} + (y*{i} - \mu*{i})^{2})\) 假设残差 $(y<em>{i} - \mu</em>{i})$ 服从一个<strong>固定尺度参数 $\gamma$</strong> 的柯西分布（即 $\gamma$ 不依赖于 $x*{i}$ 且不通过模型学习），那么整个数据集的总 NLL 为： \(NLL*{\text{total}} = n(\log(\pi) + \log(\gamma)) + \sum*{i} \log(\gamma^{2} + (y*{i} - \mu*{i})^{2})\)</p> <p><strong>关键联系:</strong> 如果我们将我们提出的损失函数中的 $\epsilon$ 视为固定的尺度参数平方，即 $\epsilon = \gamma^{2}$，那么： \(L*{\text{CauchyLike}} = \sum*{i} \log((y*{i} - \mu*{i})^{2} + \gamma^{2})\) 可以看到， $L_{\text{CauchyLike}}$ 与 $NLL_{\text{total}}$ 中依赖于模型预测 $\mu_{i}$ 的部分完全一致，两者仅相差一个不依赖于 $\mu_{i}$ 的常数项 $n(\log(\pi) + \log(\gamma))$。</p> <p><strong>结论:</strong> 因此，最小化损失函数 $\sum_{i} \log((y_{i} - \mu_{i})^{2} + \epsilon)$ <strong>在数学上等价于</strong>：假设模型残差服从一个<strong>固定尺度参数 $\gamma = \sqrt{\epsilon}$ 的柯西分布</strong>，并通过最大似然估计来学习预测位置参数 $\mu_{i}$ 的模型。这为该损失函数的鲁棒性提供了坚实的概率基础，因为柯西分布是一种重尾分布，对异常值天然不敏感。在 M 估计理论中，这类损失函数也与 Welsch 或 Leclerc loss 相关。</p> <h2 id="4-新颖损失函数的性质与潜力">4. 新颖损失函数的性质与潜力</h2> <ul> <li> <p><strong>梯度行为:</strong> 对于之前的 $\text{Loss}<em>{\text{novel}} = \sum \log(\max(\vert y</em>{i} - \mu_{i} \vert, \epsilon))$，其梯度幅度约为 $1 / \vert y_{i} - \mu_{i} \vert$。 对于改进后的 $L_{\text{CauchyLike}} = \sum \log((y_{i} - \mu_{i})^{2} + \epsilon)$，其关于 $\mu_{i}$ 的梯度为：</p> \[\frac{\partial L_{\text{CauchyLike}}}{\partial \mu_{i}} = \sum_{i} \frac{-2(y_{i} - \mu_{i})}{(y_{i} - \mu_{i})^{2} + \epsilon}\] <p>当 $\vert y_{i} - \mu_{i} \vert$ 远大于 $\sqrt{\epsilon}$ 时，梯度幅度近似为 $2/\vert y_{i} - \mu_{i} \vert$，仍然表现出<strong>大误差对应小梯度</strong>的特性。</p> </li> <li><strong>由此产生的性质:</strong> <ul> <li><strong>极强的鲁棒性:</strong> 模型对大的异常值高度不敏感，因为它们对梯度更新的贡献很小。</li> <li><strong>自动聚焦:</strong> 优化过程自然地优先拟合具有中等到小误差的点（梯度最大的地方），有效地聚焦于数据中遵循一致模式的”最密集”或最”同质”的部分。它倾向于”忽略”那些显著偏离主要模式的点。</li> </ul> </li> <li><strong>潜在应用:</strong> <ul> <li>在存在显著异常值或受污染数据的情况下进行高度鲁棒的回归。</li> <li>探索性数据分析，以识别和建模主要的底层结构/关系，同时自动降低噪声或次要模式的权重。</li> <li>可用于识别稳定的局部关系（可能是”局部因果”的线索，但需要谨慎解释——主要是以鲁棒的方式发现强相关性）。</li> </ul> </li> </ul> <h2 id="5-关键问答--思想实验总结">5. 关键问答 / 思想实验总结</h2> <ul> <li><strong>问：与 GAMLSS/MDN 的关系？它们和我的想法一样吗？</strong> <ul> <li><strong>答：</strong> GAMLSS/MDN 在<em>技术上实现</em>了基于 $x_{i}$ 预测分布参数 $(\mu_{i}, \sigma_{i})$ 的想法。然而，”极端个体化”（每个点都是一个独特的随机变量实例，仅共享规则 $f$）的<em>哲学出发点</em>可能是一个独特的视角，在 GAMLSS/MDN 文献中通常不被强调，后者通常将其框定为对 $P(Y \vert X)$ 的灵活建模。</li> </ul> </li> <li><strong>问：在原始的分布回归设置中，仅对一个样本 $(x_{1}, y_{1})$ 使用 MLE 会发生什么？</strong> <ul> <li><strong>答：</strong> NLL 损失 $Loss = \log(\sigma_{1}) + \frac{(y_{1} - \mu_{1})^{2}}{2 \sigma_{1}^{2}}$ 仅依赖于这一点。如果模型 $f=(\mu, \sigma)$ 足够灵活，它很可能会急剧过拟合：驱动 $\mu_{1} \to y_{1}$ 和 $\sigma_{1} \to 0$，导致数值不稳定和对于任何其他输入的无用参数 $\theta$。这凸显了使用<em>多个样本</em>来约束 $\theta$ 并学习<em>共享规则</em> $f$ 的必要性。</li> </ul> </li> <li><strong>问：如果 $\sigma_{i}$ 是一个自由参数（不由模型预测）会怎样？损失是什么？</strong> <ul> <li><strong>答：</strong> 如第 3 节所推导，优化掉自由的 $\sigma_{i}$ 会得到轮廓损失 $\sum \log(\vert y_{i} - \mu_{i} \vert)$。这简化了损失，但牺牲了模型基于 $x_{i}$ <em>预测</em>不确定性 ($\sigma_{i}$) 的能力。得到的 $\sigma_{i}^{*}$ 只反映了后验的残差误差，而不是先验的不确定性估计。这证明了最初预测 $\mu_{i}$ 和 $\sigma_{i}$ 的目标的合理性。</li> </ul> </li> <li><strong>问：推导出的损失 $\sum \log(\max(\vert y_{i} - \mu_{i} \vert, \epsilon))$ 是一项独特的贡献吗？</strong> <ul> <li><strong>答：</strong> <em>数学形式</em>源自标准技术（轮廓似然）。然而，<em>提出并直接将其用作独立的鲁棒回归损失函数</em>可能是新颖的或至少是不常见的。其独特的性质（梯度 $\sim 1/error$）值得研究。贡献取决于彻底的分析以及与现有鲁棒方法的比较。</li> </ul> </li> </ul> <h2 id="6-独特性贡献论点">6. 独特性/贡献论点</h2> <ol> <li><strong>原则性来源:</strong> 源自 MLE/轮廓似然，而非纯粹的启发式方法。</li> <li><strong>独特机制:</strong> 梯度行为（$\sim 1/error$）导致极强的鲁棒性和自动数据聚焦，与 L1/L2/Huber 不同。</li> <li><strong>新工具潜力:</strong> 为鲁棒的探索性分析和核心数据模式建模提供了一种新颖的方法。</li> </ol> <h2 id="7-反对论点--挑战--风险">7. 反对论点 / 挑战 / 风险</h2> <ol> <li><strong>新颖性检查:</strong> 需要彻底的文献回顾，以确认其实质性新颖性是否超越了已知概念（轮廓似然、特定的 M 估计量）。</li> <li><strong>优化难度:</strong> 非标准的梯度行为可能给优化稳定性、收敛性以及对 $\epsilon$ 的敏感性带来挑战。需要理论保证。</li> <li><strong>比较优势:</strong> 必须通过严格的实验证明其相对于已建立的鲁棒回归技术的清晰、实际的优势。”不同”是不够的；需要在相关场景下证明其”更好”或具有独特的洞察力。</li> </ol> <h2 id="8-与现有工作的关系">8. 与现有工作的关系</h2> <ul> <li><strong>GAMLSS / MDN / 概率神经网络:</strong> 为实现分布回归方面（预测多个分布参数）提供了技术框架。我们的哲学角度有所不同。</li> <li><strong>鲁棒统计 (Robust Statistics):</strong> 这项工作属于鲁棒统计的范畴。需要与标准的 M 估计量（Huber, Tukey Biweight）、RANSAC、Theil-Sen 等进行比较。</li> <li><strong>轮廓似然 (Profile Likelihood):</strong> 推导新颖损失时使用的数学技术。</li> </ul> <h2 id="9-后续步骤--开放的研究问题">9. 后续步骤 / 开放的研究问题</h2> <ul> <li><strong>文献回顾:</strong> 深入研究轮廓似然的应用、鲁棒损失函数、M 估计量、信息论损失。$\sum \log(\vert \text{error} \vert)$ 是否在其他地方被直接使用？</li> <li><strong>理论分析:</strong> 研究新颖损失的性质：凸性、光滑性（或缺乏性）、影响函数、崩溃点、使用 SGD/Adam 的收敛性质、对 $\epsilon$ 的敏感性。</li> <li><strong>实验设计:</strong> <ul> <li>合成数据：测试对各种异常值类型（幅度、杠杆点）和噪声水平的鲁棒性。与 L1、L2、Huber 比较收敛速度和最终模型质量。</li> <li>真实世界数据：应用于已知包含异常值或复杂结构的数据集。评估性能和可解释性。</li> </ul> </li> <li><strong>范围定义:</strong> 明确定义该损失函数在哪些方面表现出色，哪些方面可能失败。它的局限性是什么？</li> <li><strong>扩展:</strong> 这个想法能否应用于高斯分布以外的其他输出分布？</li> </ul>]]></content><author><name></name></author><category term="Research"/><category term="Disco"/><category term="distributional regression"/><category term="robust loss"/><category term="machine learning"/><category term="statistics"/><summary type="html"><![CDATA[This paper proposes a distributional regression approach based on the assumption of individual random variables and introduces novel robust loss functions.]]></summary></entry><entry><title type="html">Qwen 3: Alibaba Cloud’s Latest LLM Breakthrough (and a Workflow Test)</title><link href="https://1587causalai.github.io/blog/2025/qwen-3-alibaba-cloud-llm-breakthrough/" rel="alternate" type="text/html" title="Qwen 3: Alibaba Cloud’s Latest LLM Breakthrough (and a Workflow Test)"/><published>2025-04-29T00:00:00+08:00</published><updated>2025-04-29T00:00:00+08:00</updated><id>https://1587causalai.github.io/blog/2025/qwen-3-alibaba-cloud-llm-breakthrough</id><content type="html" xml:base="https://1587causalai.github.io/blog/2025/qwen-3-alibaba-cloud-llm-breakthrough/"><![CDATA[<blockquote> <p><strong>关于这篇文章：一个博客工作流的实践与反思 (About This Post: A Blogging Workflow Practice &amp; Reflection)</strong></p> <p>这篇文章的诞生，本身就是一次探索如何更顺畅地创作和发布博客的实验。所以，除了下面关于 Qwen 3 的内容，我更想在这里记录一下<strong>它是如何被创作出来的</strong>：</p> <ol> <li><strong>起点：</strong> 我一直觉得当前的博客流程太繁琐，特别是处理元数据（Front Matter）。今天（2025-04-29）和我的 AI 助手（Gemini in Cursor）讨论这个问题，希望能找到更优化的方案。</li> <li><strong>规则制定：</strong> 我们一起分析了我现有的博文 (<code class="language-plaintext highlighter-rouge">_posts/</code>)，总结了文件名和元数据的规范，并将其固化成了一份详细的文档 <code class="language-plaintext highlighter-rouge">_journal/blogmeta_rules.md</code>。这份文档明确了英文标题、标签、描述等要求。</li> <li><strong>内容输入：</strong> 我将自己写的关于 Qwen 3 发布的原始 Markdown 文本（也就是你下面看到的主体内容）提供给 AI 助手。</li> <li><strong>AI 辅助生成：</strong> 基于我提供的内容和我们刚制定的规则 (<code class="language-plaintext highlighter-rouge">_journal/blogmeta_rules.md</code>)，AI 助手： <ul> <li>自动生成了符合规范的文件名：<code class="language-plaintext highlighter-rouge">_posts/2025-04-29-qwen-3-alibaba-cloud-llm-breakthrough.md</code>。</li> <li>自动生成了完整的 Front Matter，包括英文标题、描述、标签、分类，以及添加了 <code class="language-plaintext highlighter-rouge">toc</code> 和 <code class="language-plaintext highlighter-rouge">giscus_comments</code> 等配置。</li> <li>直接创建了这个包含元数据和原始内容的 Markdown 文件。</li> </ul> </li> <li><strong>审核与迭代：</strong> 我检查了 AI 生成的文件，确认无误。然后，我们觉得把这个创作过程本身记录下来更有意义，于是又让 AI 助手修改了标题、描述、标签，并撰写了现在你看到的这段开场白。</li> </ol> <p><strong>核心体验：</strong> 通过这次实践，我发现，<strong>一旦规则被清晰定义，AI 就能很好地接管那些重复性的、格式化的工作</strong>（比如生成文件名和元数据），让我可以更专注于内容本身。虽然 Qwen 3 的内容本身可能还需要打磨，但这个<strong>“定义规则 -&gt; AI 辅助执行”</strong> 的流程确实让发布过程感觉流畅了不少。这就是这次”实验”的主要收获。</p> </blockquote> <h2 id="引言">引言</h2> <p>2025 年 4 月 29 日，阿里巴巴云发布了 Qwen 3，这是一个标志性的大型语言模型（LLM）系列，代表了自然语言处理（NLP）领域的重大进步。Qwen 3 构建在 Qwen 2.5 的成功基础上，通过创新的模型架构、扩展的训练数据和优化的后训练流程，显著提升了性能。本文将深入探讨 Qwen 3 的功能、性能指标及其在 AI 生态系统中的定位，为开发者和研究人员提供全面的参考。</p> <h2 id="模型概览">模型概览</h2> <p>Qwen 3 系列包括密集模型和专家混合（MoE）模型，参数规模从 0.6B 到 235B，满足从轻量级设备到高性能计算的多样化需求。所有模型均在 Apache 2.0 许可下开源，促进了 AI 社区的协作与创新。以下是主要模型的概况：</p> <table> <thead> <tr> <th>模型名称</th> <th>类型</th> <th>总参数</th> <th>激活参数</th> <th>上下文长度</th> </tr> </thead> <tbody> <tr> <td>Qwen3-235B-A22B</td> <td>MoE</td> <td>2350 亿</td> <td>220 亿</td> <td>128K 令牌</td> </tr> <tr> <td>Qwen3-30B-A3B</td> <td>MoE</td> <td>300 亿</td> <td>30 亿</td> <td>128K 令牌</td> </tr> <tr> <td>Qwen3-32B</td> <td>密集</td> <td>320 亿</td> <td>320 亿</td> <td>128K 令牌</td> </tr> <tr> <td>Qwen3-14B</td> <td>密集</td> <td>140 亿</td> <td>140 亿</td> <td>128K 令牌</td> </tr> <tr> <td>Qwen3-8B</td> <td>密集</td> <td>80 亿</td> <td>80 亿</td> <td>128K 令牌</td> </tr> <tr> <td>Qwen3-4B</td> <td>密集</td> <td>40 亿</td> <td>40 亿</td> <td>32K 令牌</td> </tr> <tr> <td>Qwen3-1.7B</td> <td>密集</td> <td>17 亿</td> <td>17 亿</td> <td>32K 令牌</td> </tr> <tr> <td>Qwen3-0.6B</td> <td>密集</td> <td>6 亿</td> <td>6 亿</td> <td>32K 令牌</td> </tr> </tbody> </table> <p>旗舰模型 Qwen3-235B-A22B 以其大规模参数和高效的 MoE 架构脱颖而出，而较小的模型如 Qwen3-4B 则在性能与资源需求之间取得了平衡。例如，Qwen3-4B 的性能可媲美 Qwen2.5-72B-Instruct，显示了其高效性。</p> <p>Qwen 3 模型已在 Hugging Face、ModelScope 和 Kaggle 上发布，推荐使用 SGLang 或 vLLM 进行部署，Ollama 和 LMStudio 则适合本地使用。</p> <h2 id="关键特性">关键特性</h2> <p>Qwen 3 引入了多项创新功能，使其在众多大型语言模型中独树一帜：</p> <h3 id="混合思维模式">混合思维模式</h3> <p>Qwen 3 支持两种操作模式：</p> <ul> <li><strong>思考模式 (Think Mode):</strong> 针对需要逐步推理的复杂任务，如数学问题求解、编码或逻辑推理，模型会生成详细的思维链（Chain-of-Thought, CoT）。</li> <li><strong>非思考模式 (No-Think Mode):</strong> 优化快速响应，适合通用聊天或简单查询，提高效率。</li> </ul> <p>用户可通过提示中的 <code class="language-plaintext highlighter-rouge">/think</code> 和 <code class="language-plaintext highlighter-rouge">/no_think</code> 动态切换模式，或在代码中设置 <code class="language-plaintext highlighter-rouge">enable_thinking=True/False</code>。这一功能显著提升了模型在不同场景下的适应性。</p> <p>…</p> <h2 id="预训练与后训练">预训练与后训练</h2> <p>Qwen 3 的预训练数据高达 36 万亿令牌，覆盖 119 种语言，远超 Qwen2.5 的 18 万亿令牌。训练分为三个阶段：</p> <ol> <li><strong>阶段 1:</strong> 超过 30 万亿令牌，4K 上下文，奠定基础。</li> <li><strong>阶段 2:</strong> 增加 5 万亿令牌，聚焦 STEM、编码和推理数据。</li> <li><strong>阶段 3:</strong> 高质量长上下文数据，扩展至 32K 上下文。</li> </ol> <p>后训练采用四阶段流程，包括长 CoT 初始化、基于推理的强化学习（RL）、思维模式融合和通用 RL，优化了模型在指令遵循、创意写作和多轮对话中的表现。</p> <h2 id="性能评估">性能评估</h2> <p>Qwen 3 的性能通过多项基准测试得到验证，显示其在编码、数学和通用能力方面的卓越表现。以下是 Qwen3-235B-A22B 在关键基准测试中的得分，与其他顶级模型的对比：</p> <table> <thead> <tr> <th>基准测试</th> <th>Qwen3-235B-A22B</th> <th>DeepSeek-R1</th> <th>o1</th> <th>Grok-3</th> <th>Gemini-2.5-Pro</th> </tr> </thead> <tbody> <tr> <td>Arena-Hard</td> <td>95.6</td> <td>92.1</td> <td>92.2</td> <td>-</td> <td>-</td> </tr> <tr> <td>AIME24</td> <td>81.5</td> <td>81.3</td> <td>78.8</td> <td>-</td> <td>-</td> </tr> <tr> <td>LiveCodeBench</td> <td>70.7</td> <td>64.3</td> <td>67.6</td> <td>-</td> <td>-</td> </tr> <tr> <td>CodeR</td> <td>82.6</td> <td>79.9</td> <td>80.1</td> <td>-</td> <td>-</td> </tr> <tr> <td>Aider</td> <td>61.8</td> <td>50.9</td> <td>52.3</td> <td>-</td> <td>-</td> </tr> <tr> <td>LIVEbench</td> <td>77.1</td> <td>67.7</td> <td>70.4</td> <td>-</td> <td>-</td> </tr> <tr> <td>BCLE</td> <td>70.8</td> <td>46.8</td> <td>48.6</td> <td>-</td> <td>-</td> </tr> <tr> <td>MuLTI-CLE</td> <td>71.9</td> <td>67.7</td> <td>69.7</td> <td>-</td> <td>-</td> </tr> </tbody> </table> <p>这些数据表明，Qwen3-235B-A22B 在大多数基准测试中超越了 DeepSeek-R1 和 o1，尤其是在 Aider（61.8 vs. 50.9）和 BCLE（70.8 vs. 46.8）等任务中优势明显。Arena-Hard 得分 95.6 反映了其在复杂任务中的强大指令遵循能力，而 LiveCodeBench 和 CodeR 的高分凸显了其编码能力。</p> <p>此外，Qwen3-30B-A3B 尽管激活参数较少，仍优于 QwQ-32B，显示了 MoE 架构的高效性。Qwen3-4B 的性能甚至可媲美 Qwen2.5-72B-Instruct，表明小型模型在资源受限环境中的潜力。</p> <p>需要注意的是，部分基准数据来自社交媒体分享（如 X 平台），可能需要进一步验证以确保准确性。然而……</p> <h2 id="应用场景">应用场景</h2> <p>Qwen 3 的多功能性使其适用于众多行业和场景：</p> <p>…</p> <h2 id="未来展望和结论">未来展望和结论</h2> <p>Qwen 3 的发布不仅是技术成就，也是迈向通用人工智能（AGI）和超级人工智能（ASI）的重要一步。阿里巴巴云计划进一步扩展数据和模型规模、延长上下文长度、扩展多模态功能，并通过环境反馈改进强化学习，以增强长程推理能力。这些努力旨在打造更智能、更通用的 AI 系统。</p> <p>Qwen 3 是大型语言模型领域的里程碑，其混合思维模式、广泛的语言支持和顶级基准性能使其成为领先的 AI 模型。无论是开发者、教育工作者还是企业，Qwen 3 都提供了无与伦比的灵活性和能力。随着阿里巴巴云持续推动 AI 创新，Qwen 3 无疑将在塑造智能系统未来中发挥关键作用。</p>]]></content><author><name></name></author><category term="AI-Research"/><category term="Workflow"/><category term="ai"/><category term="llm"/><category term="qwen"/><category term="alibaba cloud"/><category term="nlp"/><category term="benchmark"/><category term="moe"/><category term="release"/><category term="workflow"/><category term="blogging"/><category term="automation"/><category term="meta"/><summary type="html"><![CDATA[Testing a streamlined blog creation workflow by documenting the Qwen 3 release, following predefined metadata rules. The focus is on the process, not just the content.]]></summary></entry><entry><title type="html">重构你的大脑</title><link href="https://1587causalai.github.io/blog/2025/mind-creation/" rel="alternate" type="text/html" title="重构你的大脑"/><published>2025-03-22T00:00:00+08:00</published><updated>2025-03-22T00:00:00+08:00</updated><id>https://1587causalai.github.io/blog/2025/mind-creation</id><content type="html" xml:base="https://1587causalai.github.io/blog/2025/mind-creation/"><![CDATA[<p>最近读了 Scott Adams 的 <strong>《Reframe Your Brain: The User Interface for Happiness and Success》（重构你的大脑：通往幸福和成功的用户界面）</strong>。 Scott Adams 可能大家更熟悉的是他的漫画作品《呆伯特 (Dilbert)》，但他同时也是一位观察敏锐的思想家，尤其擅长洞察人类行为和说服力。《Reframe Your Brain》这本书，探讨如何主动重塑心智模式</p> <p>这本书实在是太好了, 有非常多的新颖的洞见, 重新设定框架, 主动把现实理解成一个对你更有用的故事(认知重构, 心智对身体有巨大影响力), 我太需要这本书了哈哈. 尤其是在这个人工智能时代, 我们过往的很多习惯认知都需要被重构, 需要重新思考如何和这个世界打交道.</p> <p>这本书给了一个非常好的三层心智重构框架:</p> <ul> <li>你的情绪是可以自己选择的。</li> <li>与其说现实是你看到的和感受到的东西, 不如想象你周围的事物都是虚拟的现象</li> <li>你自己的各种感受和想法其实都是可以完全忽略的</li> </ul> <p>同时，书中提供了许多充满辩证和智慧的实用建议, 比如:</p> <ul> <li>与其说要找到你自己(find yourself), 不如说你要成为自己的作者(author yourself).</li> <li>使用尴尬消除 ego</li> <li>能量管理而不是时间管理</li> <li>你真正要学的不是社交技巧，而是理解他人: <ul> <li>人其实很容易被操作摆布, 所以有给 “foo 理由” 技巧</li> <li>人永远关心的是自己, 所以我们选择问别人他们自己的问题, 准备一个生活化的“自我介绍” (而非简历), 表演是最高的技术.</li> <li>你需要知道人们真正需要的是什么.</li> </ul> </li> <li>… (书中还有更多精彩内容，此处省略)</li> </ul> <p>书中还有更多精彩内容，这里就不一一列举了。总而言之，这本书我觉得我需要反复读上十遍，是一本既能打开思路又实用性极强的书，强烈推荐。</p> <p>TODO:</p> <ul> <li>后续学十遍, …</li> <li>有另外一本书叫做: 重新思考(Adam Grant), 我比较好奇这两本书的关系 <ul> <li>《Reframe Your Brain》 更侧重于个体层面心智模式的重塑和情绪管理，目标在于个人成长和幸福感提升；而 《重新思考》 则更侧重于思维方式的迭代和认知灵活性，目标在于提升决策质量和应对复杂环境的能力。两本书各有侧重，都非常值得一读。</li> </ul> </li> </ul> ]]></content><author><name></name></author><category term="thinking"/><category term="book,"/><category term="thinking,"/><category term="认知重构,"/><category term="心智模式"/><summary type="html"><![CDATA[好书分享, Scott Adams, Reframe Your Brain-The User Interface for Happiness and Success]]></summary></entry><entry><title type="html">从完成投篮动作到最小必要改动渐进式开发原则</title><link href="https://1587causalai.github.io/blog/2025/basketball/" rel="alternate" type="text/html" title="从完成投篮动作到最小必要改动渐进式开发原则"/><published>2025-03-18T00:00:00+08:00</published><updated>2025-03-18T00:00:00+08:00</updated><id>https://1587causalai.github.io/blog/2025/basketball</id><content type="html" xml:base="https://1587causalai.github.io/blog/2025/basketball/"><![CDATA[<h2 id="一篮球场上的顿悟替代目标的力量">一、篮球场上的顿悟：替代目标的力量</h2> <p>今天，我在篮球场上经历了一场颇具启发性的投篮训练，意外发现了一个有趣的现象：<strong>看似不再追求命中率，却获得了最高的命中率</strong>。通过将目标从”投进球”调整为”尽快完成投篮动作”，我的命中率从30%飙升至70%。这一经历让我开始反思，无论是篮球训练、提示词工程，还是人生目标的设定，找到合适的替代目标可能是解决复杂问题的关键。</p> <div style="text-align: center;"> <img src="https://s2.loli.net/2025/03/19/YmONaVps3Rjv5DH.png" alt="basketball shooting" width="300" height="auto"/> <p>*篮球投篮的瞬间，专注于快速完成投篮动作而非命中*</p> </div> <p>刚开始投篮时，我的目标很直接——把球投进篮筐。然而，无论我如何努力，命中率始终不高，徘徊在30%左右，有时甚至低至20%。我尝试调整心态，甚至通过冥想让自己不去执着于”投进球”的念头，但效果依然不佳，命中率停留在30%。</p> <p>后来，我决定换个思路，不再直接追求”投进球”这个最终目标，而是寻找一个<strong>替代目标（Proxy Goal）</strong>。我的第一个尝试是”完成一个好的投篮动作”，希望通过优化动作来提升命中率。然而，这个目标并没有带来明显改善，命中率依然没有起色。</p> <p>直到我尝试了另一个替代目标——”<strong>尽快完成投篮动作</strong>“，奇迹发生了。我的命中率从30%飙升到了70%。为了验证这个效果，我进行了两次10个球的投篮训练，每次都稳定达到了70%的命中率。更令人惊喜的是，在这两次快速投篮训练后，我重新将目标切换回”投进球”，命中率也提升到了60%，远超之前的水平。</p> <p>这个经历让我最大的感悟是：<strong>看似不再追求命中率，却获得了最高的命中率</strong>。直接优化”投进球”这个真实目标时，我常常事与愿违，因为影响命中率的因素太多——手感、姿势、力度、角度，甚至心理状态——反馈信号太过模糊，难以指导我的改进。而”尽快完成投篮动作”作为一个替代目标，给了我一个清晰、可控的方向，专注于过程反而间接提升了整体表现。</p> <h2 id="二替代目标的普遍性辅助线与因果智慧">二、替代目标的普遍性：辅助线与因果智慧</h2> <p>这次篮球训练让我深刻体会到替代目标的价值。<strong>当真实目标受众多因素影响，反馈信号较弱时，一个合适的替代目标可以成为更易于优化的中间指标</strong>。它就像几何题中那条绝妙的辅助线，或者物理问题中一个恰到好处的坐标系，虽然不是最终答案，却能帮助我们更高效地接近目标。</p> <div style="text-align: center;"> <img src="https://s2.loli.net/2025/03/19/6ojEfCtVXJWTwzp.png" alt="surrogate goal" width="300" height="auto"/> <p>*找到替代指标是一种创造力*</p> </div> <p>在篮球的例子中，”尽快完成投篮动作”与”投进球”之间存在很强的因果关系。快速完成动作让我减少了过多思考和犹豫，反而使投篮更自然流畅，最终提升了命中率。这种方法的核心在于，替代目标不仅简化了优化过程，还提供了更强的梯度反馈，让我能够逐步调整和改进。</p> <p>这种思维在其他领域同样适用。例如，在使用大语言模型开发服务时，我曾对模型说：”我要坚持<strong>最小必要改动渐进式开发原则</strong>。”这何尝不是一个绝佳的替代目标？开发中直接追求”完美代码”往往不现实，但通过每次只做最小的改动、测试效果、再逐步优化，我能更高效地接近最终目标。这种”最小必要改动”的策略，与篮球场上的”尽快完成投篮动作”异曲同工，都是通过聚焦于可控的中间步骤，间接提升整体表现。</p> <h2 id="三提示词工程设计替代目标的艺术">三、提示词工程：设计替代目标的艺术</h2> <p>什么是最好的提示词工程？这是我一直在思考的问题，而今天的篮球体验让我有了一个新的观点：<strong>提示词工程是设计替代目标的艺术，是将复杂任务拆解成合适中间步骤的艺术</strong>。</p> <p>在使用大语言模型（LLM）时，我们需要通过提示词（Prompt）引导模型生成符合预期的输出。但直接告诉模型”给我一个完美的答案”往往不够具体，效果有限。这时，我们需要设计一个替代目标，比如”先清晰地总结上下文信息”或”逐步回答问题的每个部分”。这些中间步骤就像篮球中的”尽快完成投篮动作”，通过聚焦于可控的子目标，间接提升最终输出的质量。</p> <p>更重要的是，设计替代目标需要人类发挥独特的作用。<strong>我们扮演着那条巧妙的辅助线的角色</strong>，需要对问题有高屋建瓴的洞察、深刻的因果智慧，以及灵光一现的创造力。只有这样，我们才能将复杂任务拆解为模型能够有效执行的中间步骤，从而充分发挥人工智能的潜力。</p> <h2 id="四提示词工程的层次从基本素养到高级技能">四、提示词工程的层次：从基本素养到高级技能</h2> <p>关于提示词工程，我认为它可以分为两个层次：</p> <ol> <li> <p><strong>基本素养：上下文管理</strong><br/> 提示词工程首先是一个上下文管理问题。确保为模型提供清晰的背景信息、明确的任务指令，这些都是提示词工程的基础。</p> </li> <li> <p><strong>高级技能：设计替代目标</strong><br/> 在此之上，设计替代目标是一种更高级的能力。它不仅需要技术层面的理解，还需要创造力和对问题的深刻洞察。比如，在一个复杂的问答任务中，我们可以先让模型”列出问题的关键点”，再逐步引导它”针对每个关键点生成详细回答”，最终合成完整的答案。这种拆解和设计的过程，正是提示词工程的艺术所在。</p> </li> </ol> <p>这种层次化的理解让我意识到，提示词工程不仅是技术工具，更是人类智慧与人工智能能力结合的桥梁。通过设计合适的替代目标，我们能让人工智能更好地服务于我们的需求。</p> <h2 id="五替代目标与人生目标追求过程的力量">五、替代目标与人生目标：追求过程的力量</h2> <p>这次篮球训练的领悟不仅让我在提示词工程上有所启发，还让我对人生目标的追求有了新的思考。<strong>当我执着于某个目标时，直接追求它可能是一个非常差的策略</strong>。真实世界的影响因素非常多，目标的达成需要太多条件的配合，多到脱离我的掌控，甚至让我的动作变形。</p> <p>在篮球训练中，我发现”尽快完成投篮动作”比直接追求”投进球”更有效。类似地，在人生中，<strong>将宏大的目标拆解为可控的中间步骤</strong>可能是更明智的选择。例如，面对一个长期职业目标，与其直接追求”成功”，不如专注于”每天完成该做的工作”或”持续提升某项技能”。这些替代目标不仅更易于管理，还能提供更清晰的反馈，帮助我逐步接近最终目标。</p> <p>这种思维方式提醒我，<strong>追求过程有时比直接追求结果更重要</strong>。正如在篮球训练中，专注于动作的完成度反而提升了命中率；在人生中，专注于每一步的努力和成长，往往能带来意想不到的成功。</p> <h2 id="六结语人类的独特价值与替代目标的力量">六、结语：人类的独特价值与替代目标的力量</h2> <p>通过这次篮球训练，我不仅提高了投篮命中率，更重要的是获得了一个全新的视角：<strong>替代目标是优化复杂任务的关键</strong>。无论是体育训练、人工智能开发，还是人生目标设定，找到合适的中间指标都能让我们事半功倍。</p> <p>在与人工智能的合作中，人类的价值无可替代。我们通过洞察力和创造力，设计出巧妙的替代目标，引导人工智能发挥其强大的能力。提示词工程不仅是上下文管理的工具，更是人类智慧与人工智能潜能结合的艺术。</p> <p>希望这个思考能启发更多人，让我们在追求个人目标和与人工智能合作时，找到更多”尽快完成投篮动作”式的奇妙替代目标，共同创造更大的价值。</p>]]></content><author><name></name></author><category term="thinking"/><category term="prompt-engineering"/><category term="AI"/><category term="思考"/><category term="basketball"/><summary type="html"><![CDATA[今天，我在篮球场上经历了一场颇具启发性的投篮训练，不仅让我对如何提高投篮命中率有了新的认识，还让我对如何给大语言模型喂提示词，甚至如何给作为智能体的自己喂提示词有了新的思考。]]></summary></entry><entry><title type="html">OpenAI 的陨落：灵魂已逝，技术壁垒坍塌，再见，CloseAI！</title><link href="https://1587causalai.github.io/blog/2025/openai-lost-soul/" rel="alternate" type="text/html" title="OpenAI 的陨落：灵魂已逝，技术壁垒坍塌，再见，CloseAI！"/><published>2025-02-20T00:00:00+08:00</published><updated>2025-02-20T00:00:00+08:00</updated><id>https://1587causalai.github.io/blog/2025/openai-lost-soul</id><content type="html" xml:base="https://1587causalai.github.io/blog/2025/openai-lost-soul/"><![CDATA[<p>OpenAI 曾是人工智能领域的耀眼明星，其技术创新和影响力一度无人能及。然而，如今的 OpenAI 正逐渐失去往日的荣光，其衰落的原因可以归结为两点：一是失去了灵魂，二是技术壁垒的崩塌。本文将从多个角度深入剖析 OpenAI 的困境——灵魂人物 Ilya Sutskever 的离去、对中国用户的无底线封锁、deepseek 开源模式的崛起、挤牙膏式发布的短视策略，以及 Grok 和 Claude 等竞争对手的威胁。这些因素共同指向一个结论：OpenAI 的失败似乎已成定局，而 CEO Sam Altman 难逃其责。</p> <h2 id="灵魂人物陨落openai-的精神内核崩解">灵魂人物陨落：OpenAI 的精神内核崩解</h2> <p>伊利亚·苏茨克维 (Ilya Sutskever)，这位 OpenAI 的联合创始人兼首席科学家，是这家公司真正的灵魂人物。他的名字，与人工智能最前沿的突破紧密相连。他的离去，不仅仅是一位顶尖科学家的流失，更象征着 OpenAI 精神内核的崩塌。失去了 Sutskever，创新步伐显著放缓。一个失去灵魂的公司，如何能在 AI 领域的激烈竞争中继续称霸？ 一个没有灵魂的企业，注定走向平庸和衰落。</p> <h2 id="罪恶的歧视无底线封锁与侮辱中国用户">罪恶的歧视：无底线封锁与侮辱中国用户</h2> <p>OpenAI 对中国用户的封锁政策堪称自毁长城，其无底线行为令人愤怒。中国用户若想使用 OpenAI 的顶级付费服务（如 200 美元/月的 Pro 账号），需面对重重障碍：从注册时的手机号限制，到付费和登录的层层验证，其难度之高，堪称全球独一份！</p> <p>更令人发指的，是 OpenAI 对中国用户的公然侮辱。一位中国用户，历尽千辛万苦，成功订阅了每月 200 美元的 Pro 账号，却发现在中国大陆登录时，OpenAI 竟然使用弱智模型来糊弄他！同一账号，同一对话，在日本登录却能畅享所有先进模型！这种赤裸裸的歧视和侮辱，是对中国用户尊严的践踏，是任何有良知的人都无法容忍的！Grok 和 Claude 虽然也有地域限制，但绝不会如此卑劣地歧视用户。OpenAI 的这种无底线行为，彻底暴露了其价值观的沦丧和灵魂的缺失！</p> <h2 id="开源浪潮汹涌技术壁垒轰然倒塌">开源浪潮汹涌：技术壁垒轰然倒塌</h2> <p>OpenAI 一直将闭源视为核心竞争力，以此构建技术壁垒。然而，开源的力量如同滔天巨浪，正在无情地冲击着 OpenAI 的”技术堡垒”。DeepSeek 等开源项目的崛起，证明了开源模型完全可以媲美甚至超越闭源模型。开源已是大势所趋，是人工智能的未来！</p> <p>在开源浪潮的冲击下，OpenAI 引以为傲的技术壁垒正在轰然倒塌。当技术不再是秘密，当开源模型日益强大，OpenAI 的闭源模式将显得愈发落后和僵化。技术壁垒的瓦解，将彻底动摇 OpenAI 的根基。</p> <h2 id="挤牙膏式发布傲慢与短视的代名词">“挤牙膏”式发布：傲慢与短视的代名词</h2> <p>OpenAI 在产品发布上的”挤牙膏”策略，更是傲慢和短视的体现。与其推出成熟完整的产品，OpenAI 更倾向于零散发布新功能，试图以此吊住用户胃口。然而，这种做法适得其反，用户感受到的不是期待，而是厌恶和失望。他们需要的是稳定、高效的工具，而不是被迫适应频繁而琐碎的更新。这种短视策略不仅损害了用户体验，也让 OpenAI 在市场上的口碑和竞争力大幅下滑。</p> <h2 id="技术优势不再竞争对手强势崛起">技术优势不再：竞争对手强势崛起</h2> <p>OpenAI 曾经引以为傲的技术壁垒正在崩塌，竞争对手的崛起让其处境雪上加霜。xAI 的 Grok3 横空出世，登顶大模型竞技场；Claude 3 Sonnet 也在工程开发领域遥遥领先 OpenAI。越来越多的迹象表明，OpenAI 正在失去技术领先地位。Figure AI 机器人公司解除与 OpenAI 的合作，微软也减少了对 OpenAI 的独家支持，这些都预示着 OpenAI 的衰落已不可避免。</p> <h2 id="结语再见closeaisam-altman-必将为他的傲慢付出代价">结语：再见，CloseAI！Sam Altman 必将为他的傲慢付出代价！</h2> <p>OpenAI 的衰落可以归结为两个致命问题。首先，它失去了灵魂。Ilya Sutskever 的离职、对中国用户的歧视性封锁，以及 Sam Altman 领导下的战略失误，让 OpenAI 从一个充满理想的创新先锋沦为缺乏价值观的空壳。其次, Deepseek, Grok, Claude, Gemini 等竞争对手的已经崛起, 技术壁垒正在坍塌，OpenAI 的陨落已成定局。Sam Altman 的傲慢和短视，将 OpenAI 一步步推向深渊。曾经辉煌的 OpenAI，如今已沦为”CloseAI”，一个封闭、傲慢、歧视用户的”封闭人工智能”！</p> <p>再见，CloseAI！人工智能的未来，绝不属于 OpenAI 这样的”封闭帝国”，而将属于更加开放、包容、以人为本的开源世界！Sam Altman，你终将为你的傲慢和错误决策付出代价，历史会记住，是你，亲手”毁掉”了曾经充满希望的 OpenAI！</p> <p>&lt;!– [[2025-03-23]]</p>]]></content><author><name></name></author><category term="AI-Industry"/><category term="ai"/><category term="openai"/><category term="deepseek"/><category term="grok"/><category term="claude"/><summary type="html"><![CDATA[OpenAI 从开源理想主义到商业垄断，从技术创新到挤牙膏式发布，这家公司正在逐渐失去它的灵魂。本文将探讨 OpenAI 的衰落之路。]]></summary></entry><entry><title type="html">告别枯燥终端，迎接 Rich：让你的开发生活更舒心</title><link href="https://1587causalai.github.io/blog/2025/rich-terminal/" rel="alternate" type="text/html" title="告别枯燥终端，迎接 Rich：让你的开发生活更舒心"/><published>2025-02-19T00:00:00+08:00</published><updated>2025-02-19T00:00:00+08:00</updated><id>https://1587causalai.github.io/blog/2025/rich-terminal</id><content type="html" xml:base="https://1587causalai.github.io/blog/2025/rich-terminal/"><![CDATA[<p>作为一名在代码世界里摸爬滚打了多年的老兵，我每天都要和终端打交道，查看各种各样的输出信息：编译日志、程序运行状态、数据处理结果…… 说实话，以前的终端输出给我的感觉就是——<strong>单调、乏味，甚至有些让人眼花缭乱</strong>。</p> <p>黑底白字，密密麻麻，长时间盯着屏幕，眼睛容易疲劳，信息也难以快速捕捉。 相信很多开发者朋友和我一样，都默默忍受着这种”不那么友好”的终端体验。</p> <p>直到我遇到了 <strong><code class="language-plaintext highlighter-rouge">rich</code></strong> 这个 Python 包，一切都改变了！ 它就像一股清流，瞬间滋润了我那干涸已久的终端世界，让我找回了久违的 <strong>“舒适感”</strong>。</p> <h2 id="为什么-rich-让我感到如此舒服">为什么 Rich 让我感到如此”舒服”？</h2> <p>这种”舒服感”并非玄学，而是 <code class="language-plaintext highlighter-rouge">rich</code> 包实实在在的功能所带来的。它让终端输出不再是枯燥的文本流，而是<strong>色彩丰富、层次分明、赏心悦目的艺术品</strong>。</p> <p>想象一下，当你查看程序输出时，关键信息用鲜艳的颜色突出显示，表格数据整齐排列，进度条动态展示任务进度，错误信息清晰醒目…… 这种<strong>一目了然、高效获取信息</strong>的感觉，难道不让人感到身心舒畅吗？</p> <p>更重要的是，<code class="language-plaintext highlighter-rouge">rich</code> 的美观并非花哨，而是<strong>实用至上</strong>。 它通过视觉上的优化，<strong>降低了信息噪音，提升了信息密度</strong>，让我能够更快地理解程序输出，更轻松地定位问题，从而<strong>提升开发效率，减少视觉疲劳</strong>。</p> <p>这种 “润物细无声” 的舒适感，才是 <code class="language-plaintext highlighter-rouge">rich</code> 最打动我的地方。</p> <h2 id="rich-的-舒适-特性大盘点">Rich 的 “舒适” 特性大盘点</h2> <p>那么，<code class="language-plaintext highlighter-rouge">rich</code> 究竟是如何做到让终端输出如此”舒服”的呢？ 下面就让我这个”老司机”带您一探究竟：</p> <p><img src="https://s2.loli.net/2025/02/19/UZxw52NJI4DGSL8.png" alt="20250219194243"/> <img src="https://s2.loli.net/2025/02/19/SOkuPTsmlLI5ngZ.png" alt="20250219194244"/></p> <h2 id="rich-的-舒适-用武之地">Rich 的 “舒适” 用武之地</h2> <p><code class="language-plaintext highlighter-rouge">rich</code> 的应用场景非常广泛，几乎所有需要终端输出的 Python 项目都可以从中受益。 作为一名资深开发者，我总结了以下几个 <code class="language-plaintext highlighter-rouge">rich</code> 的 “舒适” 应用场景：</p> <ul> <li><strong>命令行工具 (CLI 工具):</strong> 开发命令行工具时，<code class="language-plaintext highlighter-rouge">rich</code> 可以让你的工具输出更友好、更专业，提升用户体验。</li> <li><strong>脚本和自动化任务:</strong> 在自动化脚本中使用 <code class="language-plaintext highlighter-rouge">rich</code>，可以更清晰地展示脚本运行状态、日志信息，方便监控和调试。</li> <li><strong>日志输出:</strong> 使用 <code class="language-plaintext highlighter-rouge">rich</code> 格式化日志输出，让日志信息更易于阅读和分析，提高问题排查效率。</li> <li><strong>数据科学脚本:</strong> 在数据科学脚本中使用 <code class="language-plaintext highlighter-rouge">rich</code>，可以更美观地展示数据分析结果、图表、表格，方便数据探索和结果汇报。</li> <li><strong>长时间运行任务:</strong> 对于需要长时间运行的任务，<code class="language-plaintext highlighter-rouge">rich</code> 的进度条功能可以有效缓解用户的焦虑情绪，提升用户体验。</li> </ul> <h2 id="如何开始享受-rich-的-舒适-体验">如何开始享受 Rich 的 “舒适” 体验？</h2> <p>安装 <code class="language-plaintext highlighter-rouge">rich</code> 非常简单，只需一条命令：</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install </span>rich
</code></pre></div></div> <p>然后，在你的 Python 代码中导入 <code class="language-plaintext highlighter-rouge">rich</code> 包，就可以开始使用了。 最常用的入口点是 <code class="language-plaintext highlighter-rouge">rich.print</code> 函数，它用法和 Python 内置的 <code class="language-plaintext highlighter-rouge">print</code> 函数类似，但功能更强大。</p> <p>下面是一个简单的示例，展示如何使用 <code class="language-plaintext highlighter-rouge">rich</code> 输出彩色文本和表格：</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">rich.console</span> <span class="kn">import</span> <span class="n">Console</span>
<span class="kn">from</span> <span class="n">rich.table</span> <span class="kn">import</span> <span class="n">Table</span>

<span class="n">console</span> <span class="o">=</span> <span class="nc">Console</span><span class="p">()</span>

<span class="c1"># 输出彩色文本
</span><span class="n">console</span><span class="p">.</span><span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">[bold red]Hello[/bold red] [italic blue]World[/italic blue]!</span><span class="sh">"</span><span class="p">,</span> <span class="n">justify</span><span class="o">=</span><span class="sh">"</span><span class="s">center</span><span class="sh">"</span><span class="p">)</span>

<span class="c1"># 创建表格
</span><span class="n">table</span> <span class="o">=</span> <span class="nc">Table</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="sh">"</span><span class="s">示例表格</span><span class="sh">"</span><span class="p">)</span>
<span class="n">table</span><span class="p">.</span><span class="nf">add_column</span><span class="p">(</span><span class="sh">"</span><span class="s">列 1</span><span class="sh">"</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="sh">"</span><span class="s">cyan</span><span class="sh">"</span><span class="p">)</span>
<span class="n">table</span><span class="p">.</span><span class="nf">add_column</span><span class="p">(</span><span class="sh">"</span><span class="s">列 2</span><span class="sh">"</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="sh">"</span><span class="s">magenta</span><span class="sh">"</span><span class="p">)</span>
<span class="n">table</span><span class="p">.</span><span class="nf">add_column</span><span class="p">(</span><span class="sh">"</span><span class="s">列 3</span><span class="sh">"</span><span class="p">,</span> <span class="n">justify</span><span class="o">=</span><span class="sh">"</span><span class="s">right</span><span class="sh">"</span><span class="p">,</span> <span class="n">style</span><span class="o">=</span><span class="sh">"</span><span class="s">green</span><span class="sh">"</span><span class="p">)</span>
<span class="n">table</span><span class="p">.</span><span class="nf">add_row</span><span class="p">(</span><span class="sh">"</span><span class="s">数据 1</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">数据 2</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">数据 3</span><span class="sh">"</span><span class="p">)</span>
<span class="n">table</span><span class="p">.</span><span class="nf">add_row</span><span class="p">(</span><span class="sh">"</span><span class="s">数据 4</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">数据 5</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">数据 6</span><span class="sh">"</span><span class="p">)</span>
<span class="n">table</span><span class="p">.</span><span class="nf">add_row</span><span class="p">(</span><span class="sh">"</span><span class="s">数据 7</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">数据 8</span><span class="sh">"</span><span class="p">,</span> <span class="sh">"</span><span class="s">数据 9</span><span class="sh">"</span><span class="p">)</span>

<span class="n">console</span><span class="p">.</span><span class="nf">print</span><span class="p">(</span><span class="n">table</span><span class="p">)</span>
</code></pre></div></div> <p>运行这段代码，你就会在终端中看到带有彩色文本和表格的精美输出！</p> <h2 id="总结让-rich-成为你的开发-舒适区">总结：让 Rich 成为你的开发 “舒适区”</h2> <p>作为一名资深开发者，我强烈推荐大家尝试一下 <code class="language-plaintext highlighter-rouge">rich</code> 这个 Python 包。 它不仅仅是一个简单的 “美化终端” 工具，更是一种 <strong>提升开发体验、提高工作效率</strong> 的利器。</p> <p>告别枯燥乏味的终端输出，迎接 <code class="language-plaintext highlighter-rouge">rich</code> 带来的舒适与高效，让你的开发生活更加轻松愉快！ 相信我，一旦用上 <code class="language-plaintext highlighter-rouge">rich</code>，你就再也回不去了！ 😉</p> <p>赶紧行动起来，让 <code class="language-plaintext highlighter-rouge">rich</code> 成为你的开发 “舒适区” 吧！ 如果你在使用过程中有任何心得体会，欢迎在评论区分享，让我们一起交流学习，共同进步！</p> <p><img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQlavYeq0Sci6DK83kZXd0c5hQZ6AnLfdybTcrPG0uleK7DRD_KyCdguhXo70NE" alt="rich"/></p>]]></content><author><name></name></author><category term="tools"/><category term="python"/><category term="rich"/><category term="terminal-tools"/><category term="developer-experience"/><summary type="html"><![CDATA[作为一名开发者，终端是我们每天都要打交道的工具。本文介绍了如何使用 Rich 这个 Python 包来改善终端输出体验，让开发工作更加舒适高效。]]></summary></entry><entry><title type="html">如何高效使用 DeepSeek-R1? 一些提示词工程本质思考</title><link href="https://1587causalai.github.io/blog/2025/deepseek-prompt/" rel="alternate" type="text/html" title="如何高效使用 DeepSeek-R1? 一些提示词工程本质思考"/><published>2025-01-29T00:00:00+08:00</published><updated>2025-01-29T00:00:00+08:00</updated><id>https://1587causalai.github.io/blog/2025/deepseek-prompt</id><content type="html" xml:base="https://1587causalai.github.io/blog/2025/deepseek-prompt/"><![CDATA[<p>在当今人工智能领域，一场来自东方的开源风暴正席卷全球，DeepSeek-R1 模型的横空出世，犹如破晓之光，照亮了 AI 发展的新路径。中国创业公司深度求索凭借这一创新力作，不仅在技术性能上与顶尖商业模型并驾齐驱，更以其显著的成本优势，引发各界广泛关注，从美国硅谷的科技巨头到华尔街的投资精英，目光纷纷聚焦于此，其应用程序在全球各国 App Store 免费榜单上的迅猛攀升，更是彰显了其强大的市场吸引力。</p> <h2 id="一deepseek-r1技术突破与全球反响">一、DeepSeek-R1：技术突破与全球反响</h2> <p>DeepSeek-R1 模型在多个关键领域展现出卓越性能，数学运算的精准、编程逻辑的严谨以及自然语言推理的流畅，都使其成为行业焦点。尤为值得一提的是，其成本仅为 OpenAI o1 模型的三十分之一，这一成本的大幅降低，无疑为高性能 AI 模型的广泛应用扫清了障碍，让更多企业和开发者能够触及前沿 AI 技术，开启创新之旅。</p> <p>其独特的训练方法更是引发热议，完全依赖强化学习（RL），摒弃了传统的监督微调（SFT），这一创新之举赋予了模型更强的泛化能力。在训练过程中，模型通过不断试错、自我优化，如同人类学习成长般，逐步提升推理能力，而非受限于预先定义的固定任务和格式套路，从而在多个基准测试中脱颖而出，甚至在某些领域超越了 OpenAI 的产品，为 AI 技术发展提供了全新思路。 这一突破性进展在全球范围内激起千层浪。美国前总统特朗普将其视为美国科技行业的 “警钟”，呼吁加大竞争力度，以应对来自东方的强劲挑战。OpenAI 首席执行官萨姆・阿尔特曼虽表示赞赏，但也深知竞争压力，承诺加快新模型发布步伐。而特斯拉 CEO 埃隆・马斯克则对 DeepSeek 的成本声称持怀疑态度，暗示背后可能存在更多高端芯片的隐秘投入。受此影响，技术股市场波动剧烈，纳斯达克指数在发布当天下跌 3.1%，英伟达股价暴跌近 17%，投资者开始重新审视美国公司在 AI 数据中心和基础设施领域的投资布局，美国科技巨头的市场主导地位面临前所未有的挑战。</p> <h2 id="二提示词工程的正本清源">二、提示词工程的正本清源</h2> <p>在这场技术变革浪潮中，作为实际使用者，我们最为关切的无疑是如何真正驾驭 DeepSeek-R1 这一强大模型，让其为我们的工作、学习和生活赋能。在传统大模型应用中，用户常常陷入 “咒语设计” 的困境，<strong>精心雕琢思维链（CoT）、角色扮演（Role-Play）、格式模板等提示技巧</strong>，试图通过复杂繁琐的指令来获取理想答案。然而，DeepSeek-R1 的出现打破了这一固有模式，它宛如一位更懂用户的知心伙伴，无需繁复修饰，只需我们直接提问，便能给出精准回应。</p> <p>有趣的是，广为流传的一个提示词是 “说人话”，这看似简单的话语，实则道出了 DeepSeek-R1 与众不同的特质。它更擅长与人类进行自然流畅的沟通，摒弃了以往复杂提示词如同魔法咒语般的晦涩难懂，真正回归到人机协作的本质。而这一切，得益于其构建时的创新理念，即原始地采用强化学习（RL）而非监督微调（SFT）方法。</p> <p>在主流大模型构建中，监督微调（SFT）被视为常规路径，通过预先定义大量任务和格式套路，让模型去学习模仿。但 DeepSeek-R1 另辟蹊径，坚信大模型应仿效人类学习方式，借助强化学习，在不断试错中优化自身，从而具备更强的泛化能力，不被固定任务和格式所束缚。这一理念的转变，为我们揭示了<strong>使用 AI 的 “第一性原理” —— 说清楚需求，定义好问题，提供好上下文:</strong></p> <ul> <li>你的需求是什么? 合适的定义任务和问题是和 AI 协作的关键第一步, 当需求很复杂的时候, 我们需要进行适当的拆解.</li> <li>问题背景是什么? 各种问题背景信息, 用户经验和偏好信息等一起提供给模型, 模型会基于这些信息给出更好的答案.</li> </ul> <p>当我们与 DeepSeek-R1 交互时，无需再费心琢磨那些花哨的提示技巧，而是将精力聚焦于明确自身需求。例如，在寻求写作灵感时，直接告知模型 “我需要一篇关于环保主题的文章大纲，要求涵盖当前环境问题、解决方案以及未来展望，字数在 1000 字左右”，如此清晰明确的需求描述，远胜于复杂的思维链引导。同时，定义好问题至关重要，若你是一名程序员，遇到代码报错，精准地向模型阐述 “我在使用 Python 编写爬虫程序时，遇到了 ‘requests’ 库连接超时的问题，已尝试过检查网络连接和服务器状态，但仍未解决，该如何排查？” 这样具体且聚焦的问题，能让模型迅速定位关键点，给出有效建议。此外，提供好上下文也不可或缺，若你正在进行学术研究，向模型展示相关文献资料、研究背景等上下文信息，它便能基于此为你拓展思路、补充论据。</p> <h2 id="三总结">三、总结</h2> <p>DeepSeek-R1 的诞生，无疑是人工智能领域的一个里程碑, 标志着开源AI模型的崛起。对于广大用户而言，掌握其使用方法的关键，在于深刻领悟提示词工程的本质 —— 说清楚需求，定义好问题，提供好上下文。当我们摒弃形式主义的复杂技巧，回归到与 AI 简单直接、清晰准确的沟通时，DeepSeek-R1 将成为我们最得力的助手，助力我们在 AI 时代开启高效智能的协作之旅，解锁无限可能。</p> <h2 id="追加更新">追加更新</h2> <p>2025-06-09 追加更新: 帮助IDE迅速了解你的个人信息，给你提供量身定制的问答 https://www.npmjs.com/package/@1587causalai/me-server</p>]]></content><author><name></name></author><category term="prompt"/><category term="DeepSeek-R1"/><category term="Prompt-Engineering"/><category term="LLM"/><category term="AI"/><summary type="html"><![CDATA[当普通大模型用户沉迷于魔法咒语时，真正的高手早已返璞归真。那些复杂的思维链模板、角色扮演话术，往往让需求迷失在形式主义中。与AI协作的道，在于说清楚需求, 定义好问题, 提供好上下文.]]></summary></entry><entry><title type="html">LlamaFactory 使用教程：轻松实现大模型微调</title><link href="https://1587causalai.github.io/blog/2025/llama-factory-tutorial/" rel="alternate" type="text/html" title="LlamaFactory 使用教程：轻松实现大模型微调"/><published>2025-01-04T00:00:00+08:00</published><updated>2025-01-04T00:00:00+08:00</updated><id>https://1587causalai.github.io/blog/2025/llama-factory-tutorial</id><content type="html" xml:base="https://1587causalai.github.io/blog/2025/llama-factory-tutorial/"><![CDATA[<p>各位朋友，今天我必须、一定要、强烈地安利一个神奇的工具——<strong>LlamaFactory</strong>！如果你和我一样，对微调大型语言模型充满热情，但又被各种复杂的命令行参数和环境配置搞得头大，那么请你务必认真看完这篇文章。因为，它真的会让你尖叫！</p> <p>我这篇文章将理论结合实践来写，通过两个具体步骤来展示 LlamaFactory 的强大：</p> <ol> <li>最快速地跑一个最简单的 DPO，体现它的易用性</li> <li>使用本地模型和本地数据进行 DPO，体现它的定制性</li> </ol> <h2 id="初见-llamafactory惊艳的第一印象">初见 LlamaFactory：惊艳的第一印象</h2> <p>我之前也尝试过一些微调工具，要么就是配置起来像解一道高数题，要么就是界面简陋得让人想砸键盘。但是，LlamaFactory-CLI WebUI 的出现，简直就像一道耀眼的光芒，瞬间照亮了我略显昏暗的 AI 炼丹之路！</p> <p>让我们从最简单的安装开始：</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>git clone <span class="nt">--depth</span> 1 https://github.com/hiyouga/LLaMA-Factory.git
<span class="nb">cd </span>LLaMA-Factory
pip <span class="nb">install</span> <span class="nt">-e</span> <span class="s2">".[torch]"</span>
</code></pre></div></div> <p>安装完成后，只需一行命令就能启动这个神奇的界面：</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>llamafactory-cli webui
</code></pre></div></div> <p><strong>打开浏览器，映入眼帘的界面让我惊呆了！</strong></p> <p>简洁明了的布局瞬间让人心情舒畅，各种参数选项排列有序，色彩搭配也恰到好处，完全没有那种”工程师风格”的冰冷感。这绝对是我见过最漂亮的 CLI WebUI 之一，用起来赏心悦目，效率都感觉提升了不少！</p> <h2 id="dpo-训练实战从理论到实践的完美演绎">DPO 训练实战：从理论到实践的完美演绎</h2> <p>别看界面漂亮，功能可一点都不含糊！我马上开始了一次实战训练，选择了最简单但也最能体现特点的配置：</p> <ul> <li>模型：<code class="language-plaintext highlighter-rouge">Qwen/Qwen-1_8B</code>（轻量级但效果不错的中文模型）</li> <li>数据集：<code class="language-plaintext highlighter-rouge">hh_rlhf_en</code>（内置的人类反馈数据集）</li> <li>训练方法：DPO（Direct Preference Optimization）</li> </ul> <p>点击”开始训练”后，眼前的画面让我感动得想哭：</p> <div style="text-align: center;"> <img src="https://s2.loli.net/2025/01/04/mu69nbXC7gkjowR.png" alt="训练界面" style="max-width: 85%; height: auto;"/> </div> <p><strong>这个训练过程简直就是一场视觉盛宴！</strong></p> <ul> <li>Loss 曲线平滑下降，就像一个优雅的舞者</li> <li>学习率的调整精准而富有节奏</li> <li>训练进度条稳步前进，让人心里踏实</li> <li>GPU 显存使用情况一目了然，再也不用担心爆显存</li> </ul> <p>更让我觉得贴心的是，WebUI 还贴心地生成了完整的训练命令：</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>llamafactory-cli train <span class="se">\</span>
    <span class="nt">--stage</span> dpo <span class="se">\</span>
    <span class="nt">--do_train</span> True <span class="se">\</span>
    <span class="nt">--model_name_or_path</span> Qwen/Qwen-1_8B <span class="se">\</span>
    <span class="nt">--preprocessing_num_workers</span> 16 <span class="se">\</span>
    <span class="nt">--finetuning_type</span> lora <span class="se">\</span>
    <span class="nt">--template</span> default <span class="se">\</span>
    <span class="nt">--flash_attn</span> auto <span class="se">\</span>
    <span class="nt">--dataset_dir</span> data <span class="se">\</span>
    <span class="nt">--dataset</span> hh_rlhf_en <span class="se">\</span>
    <span class="nt">--cutoff_len</span> 2048 <span class="se">\</span>
    <span class="nt">--learning_rate</span> 5e-05 <span class="se">\</span>
    <span class="nt">--num_train_epochs</span> 1.0 <span class="se">\</span>
    <span class="nt">--max_samples</span> 1000 <span class="se">\</span>
    <span class="nt">--per_device_train_batch_size</span> 2 <span class="se">\</span>
    <span class="nt">--gradient_accumulation_steps</span> 4 <span class="se">\</span>
    <span class="nt">--lr_scheduler_type</span> cosine <span class="se">\</span>
    <span class="nt">--max_grad_norm</span> 1.0 <span class="se">\</span>
    <span class="nt">--logging_steps</span> 5 <span class="se">\</span>
    <span class="nt">--save_steps</span> 100 <span class="se">\</span>
    <span class="nt">--warmup_steps</span> 0 <span class="se">\</span>
    <span class="nt">--packing</span> False <span class="se">\</span>
    <span class="nt">--report_to</span> none <span class="se">\</span>
    <span class="nt">--output_dir</span> saves/Qwen-1.8B/lora/train_2025-01-04-12-04-07 <span class="se">\</span>
    <span class="nt">--bf16</span> True <span class="se">\</span>
    <span class="nt">--plot_loss</span> True <span class="se">\</span>
    <span class="nt">--trust_remote_code</span> True <span class="se">\</span>
    <span class="nt">--ddp_timeout</span> 180000000 <span class="se">\</span>
    <span class="nt">--include_num_input_tokens_seen</span> True <span class="se">\</span>
    <span class="nt">--optim</span> adamw_torch <span class="se">\</span>
    <span class="nt">--lora_rank</span> 8 <span class="se">\</span>
    <span class="nt">--lora_alpha</span> 16 <span class="se">\</span>
    <span class="nt">--lora_dropout</span> 0 <span class="se">\</span>
    <span class="nt">--lora_target</span> all <span class="se">\</span>
    <span class="nt">--pref_beta</span> 0.1 <span class="se">\</span>
    <span class="nt">--pref_ftx</span> 0 <span class="se">\</span>
    <span class="nt">--pref_loss</span> sigmoid
</code></pre></div></div> <p>这个命令不仅仅是一串参数的组合，它展示了 LlamaFactory 对微调过程的深刻理解：使用 LoRA 降低显存占用，采用较小的学习率避免破坏预训练知识，设置合理的 batch size 和梯度累积步数…每个参数都经过精心调优。</p> <h2 id="定制化训练从示例到本地模型">定制化训练：从示例到本地模型</h2> <p>这个预览命令功能真的是太贴心了！有了它，我们就可以轻松地将这个训练过程迁移到自己的本地模型上。我用的是本地的 InternLM2-1.8B 模型，只需要将命令中的模型路径改为本地路径：</p> <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>llamafactory-cli train <span class="se">\</span>
    <span class="nt">--stage</span> dpo <span class="se">\</span>
    <span class="nt">--do_train</span> True <span class="se">\</span>
    <span class="nt">--model_name_or_path</span> /path/to/internlm2-1.8b <span class="se">\</span>
    <span class="nt">--preprocessing_num_workers</span> 16 <span class="se">\</span>
    <span class="nt">--finetuning_type</span> lora <span class="se">\</span>
    <span class="nt">--template</span> default <span class="se">\</span>
    <span class="nt">--flash_attn</span> auto <span class="se">\</span>
    <span class="nt">--dataset_dir</span> data <span class="se">\</span>
    <span class="nt">--dataset</span> hh_rlhf_en <span class="se">\</span>
    <span class="nt">--cutoff_len</span> 2048 <span class="se">\</span>
    <span class="nt">--learning_rate</span> 5e-05 <span class="se">\</span>
    <span class="nt">--num_train_epochs</span> 1.0 <span class="se">\</span>
    <span class="nt">--max_samples</span> 1000 <span class="se">\</span>
    <span class="nt">--per_device_train_batch_size</span> 2 <span class="se">\</span>
    <span class="nt">--gradient_accumulation_steps</span> 4 <span class="se">\</span>
    <span class="nt">--lr_scheduler_type</span> cosine <span class="se">\</span>
    <span class="nt">--max_grad_norm</span> 1.0 <span class="se">\</span>
    <span class="nt">--logging_steps</span> 5 <span class="se">\</span>
    <span class="nt">--save_steps</span> 100 <span class="se">\</span>
    <span class="nt">--warmup_steps</span> 0 <span class="se">\</span>
    <span class="nt">--packing</span> False <span class="se">\</span>
    <span class="nt">--report_to</span> none <span class="se">\</span>
    <span class="nt">--output_dir</span> saves/Qwen-1.8B/lora/train_2025-01-04-12-04-07 <span class="se">\</span>
    <span class="nt">--bf16</span> True <span class="se">\</span>
    <span class="nt">--plot_loss</span> True <span class="se">\</span>
    <span class="nt">--trust_remote_code</span> True <span class="se">\</span>
    <span class="nt">--ddp_timeout</span> 180000000 <span class="se">\</span>
    <span class="nt">--include_num_input_tokens_seen</span> True <span class="se">\</span>
    <span class="nt">--optim</span> adamw_torch <span class="se">\</span>
    <span class="nt">--lora_rank</span> 8 <span class="se">\</span>
    <span class="nt">--lora_alpha</span> 16 <span class="se">\</span>
    <span class="nt">--lora_dropout</span> 0 <span class="se">\</span>
    <span class="nt">--lora_target</span> all <span class="se">\</span>
    <span class="nt">--pref_beta</span> 0.1 <span class="se">\</span>
    <span class="nt">--pref_ftx</span> 0 <span class="se">\</span>
    <span class="nt">--pref_loss</span> sigmoid
</code></pre></div></div> <p>训练完成后，在 <code class="language-plaintext highlighter-rouge">saves/internlm2-1.8b/lora/dpo_train/</code> 目录下生成了训练结果：</p> <ul> <li><code class="language-plaintext highlighter-rouge">training_loss.png</code>：训练损失曲线</li> <li><code class="language-plaintext highlighter-rouge">training_rewards_accuracies.png</code>：奖励和准确率曲线</li> <li><code class="language-plaintext highlighter-rouge">adapter_model.safetensors</code>：训练得到的 LoRA 权重</li> <li>其他配置文件和中间检查点</li> </ul> <p>训练损失曲线:</p> <div style="text-align: center;"> <img src="https://s2.loli.net/2025/01/04/XDZa4zP8sL6pH7f.png" alt="训练损失曲线" style="max-width: 85%; height: auto;"/> </div> <p>LlamaFactory 确实是一个非常好用的工具，它让模型微调变得如此简单。通过实践我发现，它的 WebUI 不仅让操作变得直观，更重要的是帮助我们理解了微调过程中的各个参数和步骤。不过需要注意的是，在实际使用中，数据质量和模型选择仍然是最关键的因素。工具再好，也要有优质的数据和合适的基座模型才能训练出好的效果。更多解读理解文档请参考 <a href="https://1587causalai.github.io/llama_factory/">link</a>。</p>]]></content><author><name></name></author><category term="ml-engineering"/><category term="llm"/><category term="fine-tuning"/><summary type="html"><![CDATA[本文介绍如何使用 LlamaFactory 进行大模型微调，包括使用 WebUI 和命令行两种方式]]></summary></entry></feed>