---
layout: post
title: Let's Dance with Causality!
date: 2024-11-27
description: 探讨因果推理的本质，思考如何让 AI 能够理解因果关系
tags: causality machine-learning AI llm
categories: research
featured: true
---


2022年11月30日，ChatGPT的发布标志着人工智能进入了一个新的范式：以下一个词预测（Next Token Prediction）和规模定律（Scaling Law）为核心的大语言模型时代。这个范式在短短两年内带来了令人瞩目的突破，从GPT-4到Claude 3.5，展现出大语言模型惊人的能力。然而，这个范式也逐渐显露出其根本性挑战：高质量训练数据趋于饱和、推理算力成本难以持续扩展。面对这些瓶颈，业界和学术界正在多个方向上探索突破：探索新的规模定律(例如 OpenAI o1 模型)、多模态融合、构建持续学习能力、世界模型等。在众多方向中，我选择将研究重心放在因果推理与大语言模型的融合上。这个方向虽然充满挑战，但我相信它有潜力从根本上改变当前的范式。



## Why Should We Bet on Causality?


想象一下芯片技术的发展历程。在芯片领域，制程的提升是核心驱动力 - 从130nm到3nm，每一次制程的突破都带来了质的飞跃。这让我们思考：在AI领域，什么才是真正的"制程"？我认为，这个关键在于信息密度。

当我们谈论因果关系时，我们实际上是在讨论一种极其密集的信息形式。因果之梯定理（The Causal Hierarchy Theorem）揭示了一个惊人的事实：相关性信息相对于因果信息（包括干预信息和反事实信息）实际上是一个零测集。这意味着因果模型比纯相关性模型包含了指数级更多的信息 - 就像物理定律相对于统计规律那样，是一种本质上更加密集的信息形式。

因果思维不仅是信息密度的问题，更是人类认知的核心能力。从儿童认知发展的研究可以看到，人类天生就具备探索因果关系的倾向。如果我们希望AI能够真正理解人类意图、实现深度沟通，成为人类的得力助手，那么掌握因果思维就显得尤为重要。这也正是为什么Bengio在提出双系统理论时，将因果关系置于系统二的核心位置。


此时, 如何让 AI 具备因果思维, 掌握因果推理, 就成为了一个非常有趣且重要的问题. 



<!-- 精心设计的随机实验数据也比观测数据具备更有价值, 是挖掘因果关系的黄金准则。 -->
<!-- High-level 的解释: 
我们的观点是: 
- 正如芯片的关键在于制程, 大语言模型的信息密度也很重要, 而因果模型拥有非常最高的信息密度(例如各种物理方程)
  - 因果之梯定理告诉我们, 相关性信息相对于反事实信息是一个零测集
- 因果思维是我们人类最强大的认知工具, 是我们人类智能一个关键组成.  AI 的目的是服务人类, 成为人类的良师益友, 自然 AI 也需要掌握因果思维 -->


## Understanding Causality




<!-- 可以先来一段简单的介绍一下什么是因果关系？ -->




人类思索和运用因果关系已有数千年历史。从最简单的"按下开关，灯亮了"，到复杂的"教育如何影响收入"，因果关系无处不在，是世界运行的基本机制。在不同领域中，因果关系呈现出独特的形式：数学中是"因为...所以..."的推理链条，物理学中体现为牛顿三定律等基本规律，法律领域则是"根据...可以推断..."的证据链。

当我们谈及因果效应时，核心是 Difference-making：一个事物的改变如何导致另一个事物的变化。这与仅表示统计关联的相关性有本质区别。两个事物之间可能存在统计关联，但这并不意味着改变其中一个必然会影响另一个 - 这就是我们常说的"seeing不等同于doing"，或"相关性不等于因果关系(Correlation is not Causation)"。这也解释了为什么随机对照实验在因果推断中如此重要，以至于被称为"黄金准则"。


因果推理其实理解起来并不容易, 比如用于观测数据因果效应估计的逆概率加权(IPW)方法, Bready Neal 教材的公式 (7.2.1): 

$$\begin{align}
\hat{\tau} &= \frac{1}{n}\sum_i \left(\frac{\mathbb{1}(t_i = 1)y_i}{\hat{e}(w_i)} - \frac{\mathbb{1}(t_i = 0)y_i}{1-\hat{e}(w_i)}\right) \\
&= \frac{1}{n_1}\sum_{i:t_i=1}\frac{y_i}{\hat{e}(w_i)} - \frac{1}{n_0}\sum_{i:t_i=0}\frac{y_i}{1-\hat{e}(w_i)}
\end{align}$$

通过量纲分析可以得知第2个等号是错的, 这个错误反应大家认为只需简单直接通过倾向得分加权以后, 就可以利用观测数据估计因果效应. 可见即使是有名教材在耳熟能详的问题上也会犯误, 足以说明理解因果关系并不容易. 

更进一步, 我们有几个著名悖论需要细致理解因果关系, 才能避免犯错:
- 辛普森悖论：治疗效果的迷思
加州大学伯克利分校在20世纪70年代的入学数据引发了一场争议。总体数据显示，男性申请者的录取率高于女性申请者，这看似反映了性别歧视。然而，当研究者们分院系统计时，却发现在每个院系中，女性的录取率都略高于男性。这个看似矛盾的现象就是著名的辛普森悖论。
究其原因，女性倾向于申请竞争更激烈的院系（如英语系、历史系），而男性则更多申请竞争相对较小的院系（如工程系）。这提醒我们，观察到的统计相关性可能会误导我们对因果关系的判断，必须考虑潜在的混淆因素。
- Berkson悖论：医院里的反直觉现象
想象一家医院的研究人员在研究两种疾病A和B之间的关系。他们发现，在住院病人中，患有疾病A的人较少患有疾病B，反之亦然，呈现出负相关。这个发现似乎暗示这两种疾病之间存在某种相互抑制的关系。
但实际上，这种负相关是一种统计假象。因为人们通常只有在病情较重时才会住院。如果一个人同时患有A和B两种疾病，即使每种疾病的严重程度都不足以单独导致住院，但两种疾病的叠加效应可能会导致住院。这就导致了在住院人群中观察到的负相关，这就是Berkson悖论。
- 替代指标悖论：一个代价惨重的教训
1989年，辉瑞公司开发的抗心律失常药物恩卡尼（Encainide）获得了FDA的批准。这个药物之所以获批，是因为它能有效降低心电图上的室性早搏次数——这是当时普遍认为的心脏病发作风险的重要指标。
然而，后续的CAST研究揭示了一个触目惊心的事实：服用该药物的心梗后患者的死亡率反而增加了2-3倍。原来，虽然药物确实减少了早搏次数，但它同时也增加了更严重的心律失常风险。这个案例告诉我们，替代指标（室性早搏次数）的改善并不一定意味着真正关心的结果（患者存活率）会改善。这就是替代指标悖论的典型案例，它提醒我们在医学研究中必须谨慎评估因果关系。


在众多因果性视角中，我特别关注其不变性特征：Causality is Invariance Across Different Units。就像物理定律一样，每个因果关系都有其适用范围，都是context-specific的。每个具体场景（context）定义了一个子群体，其中的个体虽然各不相同，但都遵循相同的因果关系。这启发我们将研究重点放在个体(individual/unit)的异质性（heterogeneity）和同质性（Homogeneity）上，将其作为因果研究的基本要素(Primitive), 所以我们开发了基于 individual causality 的 DiscoSCM 框架[1]. 



## The DiscoSCM Framework

DiscoSCM（Distribution-consistency Structural Causal Models）作为基于个体因果（Individual Causality）的框架，引��了专门的随机变量U来表征个体特征。这使得描述因果机制的结构方程从传统的 $$Y = f(X, E)$$ 扩展为 $$Y = f(X, E; U)$$，其中 $$X$$ 是原因变量，$$E$$ 是外生噪声，而 $$U$$ 则表征该个体。

这个框架一个根本的创新在于对因果结果随机性来源的重新诠释。在主流因果框架中，SCM将观察到的具体结果 $$Y=y$$ 归因于外生噪声 $$E$$ 的特定实现值，而 PO（Potential Outcome）框架则将其归因于特定个体的选择。DiscoSCM 融合了这两者，明确指出：观察到的具体结果 $$Y=y$$ 是由外生噪声 $$E$$ 的实现值和个体表征 $$U$$ 的取值共同决定的。 

Variables in Counterfactual World 本质是不可观测的, 如何建立其与 Observable Variables in Factual World 的联系涉及到了因果推理的本质.  DiscoSCM 这种双重决定性的观点直接启发我们对因果推理的最基础假设的反思。传统框架依赖的一致性规则（consistency rule）规定：当观察到处理 $$X=x$$ 时，该特定 treatment level 的反事实结果 $$Y(x)$$ 必须等于实际观察结果 $$Y$$。而DiscoSCM提出的**分布一致性规则**则指出：给定处理 $$X=x$$ 和个体表征 $$U=u$$ 时，反事实结果 $$Y(x)$$ 与实际结果 $$Y$$ 的分布应当一致，即：

$$X=x, U=u \Rightarrow Y(x) =_d Y$$

这两种一致性规则的区别可以通过具体例子来理解：假设我们观察到某平台上一群高补贴用户具有高留存（$$X=1, Y=1$$）。传统的consistency rule会推导出 $$Y(1)=1$$，暗示只要给这群用户高补贴就必然导致高留存。这显然忽视了一个现实：部分用户的高留存可能仅仅源于偶然因素。相比之下，Distribution-consistency 能够更准确地刻画这种情况：它承认在相同条件下，反事实结果 $$Y(1)$$ 会呈现出一定的分布，从而能够区分出多少留存应归因于补贴政策，多少应归因于随机因素。这种差异在更多场景中都能体现。比如，当我们问"一个考上清华计算机系的学生，如果回到过去重新高考，有多大概率能再次考上？" 显然不会是 100%，因为即使在完全相同的条件下, 承认不可控制的 Exogenous Noise 更符合我们对现实世界的理解, 所以这类问题本质上需要 Distribution-consistency 框架来回答。请注意因果信息有三个层级(seeing, doing, imagining), 这两个例子都是 imagining 的例子, 事实上 DiscoSCM 和 SCM 在前面两个层级是数学上等价的[1]. 



基于个体因果的DiscoSCM框架具有强大的解释力，能够为多个经典因果悖论提供更直观合理的解释：

> Simpson's Paradox（辛普森悖论）

以性别歧视为例，当我们研究性别（$$X$$）与录取结果（$$Y$$）之间的因果关系时，判断性别歧视的本质是考察对随机选取的个体（$$U$$），其在不同性别下的潜在结果$$Y(0)$$和$$Y(1)$$是否存在显著差异。然而，现实中观察到的男女群体（$$X=0,1$$）与随机个体（$$U$$）的分布并不一致，这种选择偏差导致直接计算的男女录取率并不能作为 $$Y(x)$$ 的无偏估计，因此不能直接用于推断性别歧视的存在。

> Berkson's Paradox（伯克森悖论）

当我们关心两种疾病在一般人群中是否独立时，实际上是在考虑对随机个体而言这两个事件是否独立。然而，如果我们的数据仅来自住院病人这个特殊群体（有偏总体），那么在这个群体中观察到的负相关并不能用来推断一般人群中两种疾病的独立性。

> Surrogate Endpoint Paradox（替代终点悖论）

在研究用药（$$X$$）、替代指标（$$S$$）和最终结果（$$Y$$）的因果链时，即使我们观察到$$X$$对$$S$$以及$$S$$对$$Y$$都有显著的因果效应，也不能直接推断$$X$$对$$Y$$存在显著因果效应。从个体因果的视角来看，这种现象可能源于人群的异质性：对某些人而言，$$X$$影响$$S$$但$$S$$不影响$$Y$$；对另一些人而言，$$X$$不影响$$S$$但$$S$$影响$$Y$$。当这种异质性存在时，即使分别观察到$$X$$到$$S$$和$$S$$到$$Y$$的因果效应，在整体人群水平上$$X$$对$$Y$$的复合因果效应也可能不显著。


DiscoSCM框架不仅具有强大的解释力，还推导出了一系列重要的理论结果。其中一个很有意思的结论是：

$$
\begin{align}
E[Y(t)|T=t, Y=y] &= E\bigg[\frac{Y \mathbb{1}_{T=t}}{P(T=t)} \cdot \frac{P(Y=y|T=t; U)}{P(Y=y|T=t)}\bigg] 
\end{align}
$$

这个公式为我们提供了一个估计反事实的实用方法。比如，在前面的例子中，只要我们能够建立个体层面的模型 $$P(Y=y|T=t; U)$$，就能够准确计算出：高留存用户中有多少比例应归因于高补贴政策，或者考上清华的结果中有多少比例应归因于学生的实际能力。这种精确的归因能力，使得DiscoSCM框架不仅在理论上优雅，在实践中也具有重要价值。


至此, 我们已经把这个新因果框架的来龙去脉介绍清楚了, 接下来将会介绍我们在这个框架下的一些人工智能应用的探索. 


## Our Exploration on AI Inspired by Causality



 <!-- 因果之梯为信息的分层和处理提供了理论基础. 这启发我们思考, 如何融合 -->



如果将人工智能视作一个信息处理的自动化系统，那么信息的表征和融合就成为核心问题之一。使用概率分布来表征信息是一种常见做法，这立即引出一个关键问题：这个分布应该定义在什么样的概率空间上？DiscoSCM框架给了我们重要启发：任何证据或观察都与某个特定的子总体（sub-population）相关联。因此，我们可以用子总体来表征信息，这为信息表示提供了一个新的视角。

我们使用这个思路来审视大语言模型（LLM）。作为一个下一个词预测器（next token predictor），LLM本质上是在给定上下文（context）的条件下，生成token空间上的一个分布。这个分布定义了token空间的一个子总体，从而完成了信息处理过程。在实际应用中，我们常常需要通过奖励信息（reward）来引导生成过程，使模型更好地对齐人类偏好。这本质上是一个信息融合问题：如何将奖励信息与模型的原始分布有效融合？

DPO（Direct Preference Optimization）提供了一种解决方案。我们提出了一个简洁的信息融合算子 $$\odot$$ 来重新诠释DPO算法的核心机制 [3]：

$$
\begin{equation}
    \pi(\cdot|x) = \pi_{ref}(\cdot|x) \odot p_r(\cdot|x;\beta)
\end{equation}
$$

其中，$$p_r(\cdot|x;\beta)$$ 表示对奖励函数 $$r(\cdot|x)$$ 应用温度参数为 $$\beta$$ 的softmax变换得到的Boltzmann探索概率分布：

$$
\begin{equation}
    p_r(\cdot|x;\beta) \propto \exp(\frac{1}{\beta} r(x, \cdot))
\end{equation}
$$


大语言模型需要对齐才能生成更符合人类偏好的内容, 自然会问是符合哪些人类偏好? 不同国家, 不同文化背景, 不同性别, 不同年龄的人类偏好显然是不同的, 所以我们更需要个性化的对齐用户偏好. 这就直接有两个大语言模型优化思路:
- 把个性化加入到奖励建模, 考虑更好的 reward function design 来建模人类偏好.
- 考虑因果思维链: Context --> User Representation --> Response, 将其融入到模型训练中.
- 思考构建评测大语言模型 Implicit Personalizatin 能力的数据集.

大语言模型的对齐问题不应该追求一个统一的"人类偏好"标准。事实上，不同国家、文化背景、性别、年龄的用户具有显著不同的价值观和偏好。这种多样性启发我们思考：如何实现大语言模型的个性化对齐？我们提出三个相互关联的研究方向：

1. **个性化奖励建模**：将用户表征及其偏好特性明确纳入奖励函数设计的考虑中，使模型能够针对不同用户群体生成更适合的内容。

2. **因果链条的融入**：新增构建 Context → User Representation → Response 的因果思维链，将其作为模型训练的核心机制，使个性化成为模型的内在能力而非外部调整。

3. **评测框架的建立**：构建专门的数据集来评测模型的隐式个性化（Implicit Personalization）能力，为个性化对齐的研究提供客观的衡量标准。


## Conclusion and Future Work

<!-- 总结和展望 -->

本文从因果推理的视角重新审视了大语言模型的发展。我们认为，当前以Next Token Prediction为核心的范式虽然取得了显著成果，但也面临着数据效率低、推理成本高等挑战。通过将因果推理与大语言模型相结合，我们看到了突破这些瓶颈的可能性。

特别地，我们提出的DiscoSCM框架通过引入个体表征，为因果推理提供了新的视角。这个框架不仅能够优雅地解释多个经典的因果悖论，还为精确的归因分析提供了理论基础。更重要的是，这个框架启发我们思考如何更好地表征和融合信息，为大语言模型的改进提供了新的思路。

在实践层面，我们将这些理论见解应用到了大语言模型的个性化对齐问题上。通过将用户表征纳入考虑，我们提出了包括个性化奖励建模、因果链条融入和评测框架建立在内的完整研究方案。

展望未来，我们认为有以下几个值得深入探索的方向：

1. **因果结构的自动发现**：研究如何从大规模语言数据中自动发现和学习因果结构，使模型能够更好地理解事物之间的因果关系。

2. **高效的个性化机制**：探索在保持模型基础能力的同时，如何实现轻量级的个性化调整，使模型能够更好地适应不同用户的需求。

3. **可解释性的提升**：利用因果框架提供的清晰结构，提高模型决策过程的可解释性，使我们能够更好地理解和控制模型的行为。

4. **理论与实践的深度融合**：进一步探索如何将因果推理的理论见解转化为实际可行的算法和架构设计。

我们相信，随着因果推理与大语言模型的深度融合，我们将能够构建出更加智能、更具个性化、也更值得信赖的AI系统。这不仅将推动技术的进步，也将帮助我们更好地理解和服务人类的多样性需求。





## References
<!-- 参考文献 -->


[1] Heyang Gong, Chaochao Lu, and Yu Zhang. Distribution-consistency Structural Causal Models. arXiv preprint arXiv:2401.15911. 2024.

[2] Judea Pearl, and Dana Mackenzie. The book of why: the new science of cause and effect[M]. Basic books, 2018.

[3] Heyang Gong. A Novel Information Fusion Framework Based on a Simple Stochastic Aggregation Operator with Applications in Decision-Making. 2024.
